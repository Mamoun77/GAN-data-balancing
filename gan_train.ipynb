{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd7c9364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "from tqdm.auto import tqdm\n",
    "from torch.nn.utils import spectral_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d288ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA L4\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23699ab3",
   "metadata": {},
   "source": [
    "## Calculating the Normalization mean and std specifically for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cd84e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09532661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'labels', 'indices'])\n"
     ]
    }
   ],
   "source": [
    "minority_data = torch.load('class_0_reduced.pt')\n",
    "print(minority_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "901d32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "minority_data = torch.load('class_0_reduced.pt')\n",
    "minority_dataset = TensorDataset(minority_data['data'], minority_data['labels'])\n",
    "minority_loader = DataLoader(minority_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "minority_class_idx = 0\n",
    "minority_class_name = \"Class 0\"\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a4316f",
   "metadata": {},
   "source": [
    "#  Defining the Models Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec94b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class VanillaGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, img_size=128):\n",
    "        super(VanillaGenerator, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(1024,img_size * img_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 1, self.img_size, self.img_size)\n",
    "        return img\n",
    "\n",
    "# Discriminator\n",
    "class VanillaDiscriminator(nn.Module):\n",
    "    def __init__(self, img_size=128):\n",
    "        super(VanillaDiscriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(img_size * img_size, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "945f084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGANGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, img_channels=1):\n",
    "        super().__init__()\n",
    "        self.init_size = 7  # Changed from 4 to 7 (28/4 = 7)\n",
    "        self.l1 = nn.Linear(latent_dim, 128 * self.init_size ** 2)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),  # 7->14\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, img_channels, 4, 2, 1),  # 14->28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        return self.model(out)\n",
    "\n",
    "class DCGANDiscriminator(nn.Module):\n",
    "    def __init__(self, img_channels=1):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            spectral_norm(nn.Conv2d(img_channels, 64, 4, 2, 1)),  # 28->14\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            spectral_norm(nn.Conv2d(64, 128, 4, 2, 1)),  # 14->7\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            spectral_norm(nn.Conv2d(128, 1, 7, 1, 0))  # 7->1\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        return torch.sigmoid(out.view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbf4b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGANGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, num_classes=10, img_channels=1):\n",
    "        super(CGANGenerator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, latent_dim)\n",
    "        self.init_size = 7\n",
    "        self.l1 = nn.Linear(latent_dim * 2, 128 * self.init_size ** 2)\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),  # 7->14\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, img_channels, 4, 2, 1),  # 14->28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, labels):\n",
    "        label_input = self.label_emb(labels)\n",
    "        gen_input = torch.cat([z, label_input], -1)\n",
    "        out = self.l1(gen_input)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "class CGANDiscriminator(nn.Module):\n",
    "    def __init__(self, num_classes=10, img_channels=1):\n",
    "        super(CGANDiscriminator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, 28 * 28)  # Changed from 128*128\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(img_channels + 1, 64, 4, stride=2, padding=1),  # 28->14\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),  # 14->7\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 1, 7, stride=1, padding=0),  # 7->1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, img, labels):\n",
    "        label_input = self.label_emb(labels).view(labels.shape[0], 1, 28, 28)\n",
    "        d_in = torch.cat([img, label_input], 1)\n",
    "        validity = self.model(d_in)\n",
    "        return validity.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1122af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torchvision.utils import save_image\n",
    "from scipy import linalg\n",
    "import numpy as np\n",
    "from torchvision.models import inception_v3\n",
    "\n",
    "# FID Score Calculation\n",
    "def calculate_fid(real_images, fake_images, device):\n",
    "    \"\"\"Calculate Fr√©chet Inception Distance\"\"\"\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).to(device)\n",
    "    inception_model.fc = nn.Identity()\n",
    "    inception_model.eval()\n",
    "    \n",
    "    def get_activations(images):\n",
    "        with torch.no_grad():\n",
    "\n",
    "            if images.shape[1] == 1:\n",
    "                images = images.repeat(1, 3, 1, 1)\n",
    "                \n",
    "            # Resize to 299x299 for Inception\n",
    "            images_resized = nn.functional.interpolate(images, size=(299, 299), mode='bilinear', align_corners=True)\n",
    "            pred = inception_model(images_resized)\n",
    "        return pred.cpu().numpy()\n",
    "    \n",
    "    act_real = get_activations(real_images)\n",
    "    act_fake = get_activations(fake_images)\n",
    "    \n",
    "    mu_real, sigma_real = act_real.mean(axis=0), np.cov(act_real, rowvar=False)\n",
    "    mu_fake, sigma_fake = act_fake.mean(axis=0), np.cov(act_fake, rowvar=False)\n",
    "    \n",
    "    diff = mu_real - mu_fake\n",
    "    covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n",
    "    \n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    \n",
    "    fid = diff.dot(diff) + np.trace(sigma_real + sigma_fake - 2 * covmean)\n",
    "    return fid\n",
    "\n",
    "# Save sample images\n",
    "def save_sample_images(generator, epoch, latent_dim, save_path, num_samples=25, labels=None):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_samples, latent_dim).to(device)\n",
    "        if labels is not None:\n",
    "            # For CGAN\n",
    "            sample_labels = torch.full((num_samples,), labels, dtype=torch.long).to(device)\n",
    "            gen_imgs = generator(z, sample_labels)\n",
    "        else:\n",
    "            gen_imgs = generator(z)\n",
    "        \n",
    "        save_image(gen_imgs.data, f\"{save_path}/epoch_{epoch}.png\", nrow=5, normalize=True)\n",
    "    generator.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2f55a9",
   "metadata": {},
   "source": [
    "# Defining the Training Loop for each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55394c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(discriminator, real_imgs, fake_imgs, labels=None):\n",
    "    batch_size = real_imgs.size(0)\n",
    "    alpha = torch.rand(batch_size, 1, 1, 1).to(device)\n",
    "    \n",
    "    interpolates = (alpha * real_imgs + (1 - alpha) * fake_imgs).requires_grad_(True)\n",
    "    \n",
    "    if labels is not None:\n",
    "        d_interpolates = discriminator(interpolates, labels)\n",
    "    else:\n",
    "        d_interpolates = discriminator(interpolates)\n",
    "    \n",
    "    fake = torch.ones(batch_size, 1).to(device).requires_grad_(False)  # Changed\n",
    "    \n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,  # Changed\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    \n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6601694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vanilla_gan(generator, discriminator, dataloader, num_epochs=100, starting_epoch=1, latent_dim=100, \n",
    "                      save_path='generated_images/vanilla_gan', model_path='models/vanilla_gan'):\n",
    "    \n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    \n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.00005, betas=(0.5, 0.999))\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # Create metrics file\n",
    "    metrics_file = f'{save_path}/training_metrics.txt'\n",
    "    with open(metrics_file, 'w') as f:\n",
    "        f.write(\"Epoch,Time(s),D_Loss,G_Loss,FID_Score\\n\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STARTING VANILLA GAN TRAINING - {num_epochs} EPOCHS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    for epoch in range(starting_epoch, num_epochs + 1):\n",
    "        epoch_start = time.time()\n",
    "        epoch_d_loss = 0\n",
    "        epoch_g_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for i, (imgs, _) in enumerate(dataloader):\n",
    "            batch_size = imgs.size(0)\n",
    "            real_imgs = imgs.to(device)\n",
    "\n",
    "            \n",
    "            # Labels\n",
    "            real_labels = torch.ones(batch_size, 1).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "            \n",
    "            if epoch <= 10 or i % 2 == 0:\n",
    "                optimizer_D.zero_grad()\n",
    "                real_discriminator_prediction = discriminator(real_imgs)\n",
    "                real_loss = criterion(real_discriminator_prediction, real_labels)\n",
    "                \n",
    "                z = torch.randn(batch_size, latent_dim).to(device)\n",
    "                fake_imgs = generator(z)\n",
    "                fake_loss = criterion(discriminator(fake_imgs.detach()), fake_labels)\n",
    "                \n",
    "                gp = compute_gradient_penalty(discriminator, real_imgs, fake_imgs)\n",
    "                d_loss = (real_loss + fake_loss) / 2 + 5 * gp\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "            else:\n",
    "                d_loss = torch.tensor(0.0)\n",
    "\n",
    "            # Train Generator\n",
    "            optimizer_G.zero_grad()\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            gen_imgs = generator(z)\n",
    "            g_loss = criterion(discriminator(gen_imgs), real_labels)\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        # Calculate average losses\n",
    "        avg_d_loss = epoch_d_loss / num_batches\n",
    "        avg_g_loss = epoch_g_loss / num_batches\n",
    "        \n",
    "\n",
    "        fid_score = 0.0\n",
    "        if epoch % 2 == 0:\n",
    "            with torch.no_grad():\n",
    "                real_batch = next(iter(dataloader))[0][:128].to(device)\n",
    "                z = torch.randn(128, latent_dim).to(device)\n",
    "                fake_batch = generator(z)\n",
    "                fid_score = calculate_fid(real_batch, fake_batch, device)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Epoch {epoch} | Time: {epoch_time:.2f}s\")\n",
    "        print(f\"  D_Loss: {avg_d_loss:.6f} | G_Loss: {avg_g_loss:.6f}\")\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"  FID Score: {fid_score:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        # Save metrics to file\n",
    "        with open(metrics_file, 'a') as f:\n",
    "            f.write(f\"{epoch},{epoch_time:.2f},{avg_d_loss:.6f},{avg_g_loss:.6f},{fid_score:.4f}\\n\")\n",
    "        \n",
    "        save_sample_images(generator, epoch, latent_dim, save_path)\n",
    "        \n",
    "        # Save model after epoch 5\n",
    "        if epoch > 20 and epoch % 4 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'generator_state_dict': generator.state_dict(),\n",
    "                'discriminator_state_dict': discriminator.state_dict(),\n",
    "                'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "                'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "            }, f\"{model_path}/model_epoch_{epoch}.pt\")\n",
    "\n",
    "        del imgs, real_imgs, fake_imgs, gen_imgs, z\n",
    "        if i % 10 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"VANILLA GAN TRAINING COMPLETE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return generator, discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5843f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dcgan(generator, discriminator, dataloader, starting_epoch=1, num_epochs=100, latent_dim=100,\n",
    "                save_path='generated_images/dcgan', model_path='models/dcgan'):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    \n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.00005, betas=(0.5, 0.999))\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    metrics_file = f'{save_path}/training_metrics.txt'\n",
    "    with open(metrics_file, 'w') as f:\n",
    "        f.write(\"Epoch,Time(s),D_Loss,G_Loss,FID_Score\\n\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STARTING DCGAN TRAINING - {num_epochs} EPOCHS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    for epoch in range(starting_epoch, num_epochs + starting_epoch):\n",
    "        epoch_start = time.time()\n",
    "        epoch_d_loss = 0\n",
    "        epoch_g_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for i, (imgs, _) in enumerate(dataloader):\n",
    "            batch_size = imgs.size(0)\n",
    "            real_imgs = imgs.to(device)\n",
    "\n",
    "            real_labels = torch.ones(batch_size, 1).to(device) \n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "            \n",
    "            if epoch <= 10 or i % 3 == 0:\n",
    "                optimizer_D.zero_grad()\n",
    "                real_loss = criterion(discriminator(real_imgs), real_labels)\n",
    "                \n",
    "                z = torch.randn(batch_size, latent_dim).to(device)\n",
    "                fake_imgs = generator(z)\n",
    "                fake_loss = criterion(discriminator(fake_imgs.detach()), fake_labels)\n",
    "                \n",
    "                gp = compute_gradient_penalty(discriminator, real_imgs, fake_imgs)\n",
    "                d_loss = (real_loss + fake_loss) / 2 + 2 * gp\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "            else:\n",
    "                d_loss = torch.tensor(0.0)\n",
    "\n",
    "            # Train Generator\n",
    "            optimizer_G.zero_grad()\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            gen_imgs = generator(z)\n",
    "            g_loss = criterion(discriminator(gen_imgs), real_labels)\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_d_loss = epoch_d_loss / num_batches\n",
    "        avg_g_loss = epoch_g_loss / num_batches\n",
    "        \n",
    "        # Calculate FID every 2 epochs\n",
    "        fid_score = 0.0\n",
    "        if epoch % 2 == 0:\n",
    "            with torch.no_grad():\n",
    "                real_batch = next(iter(dataloader))[0][:128].to(device)\n",
    "                z = torch.randn(128, latent_dim).to(device)\n",
    "                fake_batch = generator(z)\n",
    "                fid_score = calculate_fid(real_batch, fake_batch, device)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        print(f\"Epoch {epoch} | Time: {epoch_time:.2f}s\")\n",
    "        print(f\"  D_Loss: {avg_d_loss:.6f} | G_Loss: {avg_g_loss:.6f}\")\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"  FID Score: {fid_score:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        with open(metrics_file, 'a') as f:\n",
    "            f.write(f\"{epoch},{epoch_time:.2f},{avg_d_loss:.6f},{avg_g_loss:.6f},{fid_score:.4f}\\n\")\n",
    "        \n",
    "       \n",
    "        save_sample_images(generator, epoch, latent_dim, save_path)\n",
    "        \n",
    "        if epoch > 20 and epoch % 4 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'generator_state_dict': generator.state_dict(),\n",
    "                'discriminator_state_dict': discriminator.state_dict(),\n",
    "                'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "                'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "            }, f\"{model_path}/model_epoch_{epoch}.pt\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"DCGAN TRAINING COMPLETE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return generator, discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38a0518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cgan(generator, discriminator, dataloader, minority_class_idx, num_epochs=100, starting_epoch=1, \n",
    "               latent_dim=100, save_path='generated_images/cgan', model_path='models/cgan'):\n",
    "    \n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.00005, betas=(0.5, 0.999))\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    metrics_file = f'{save_path}/training_metrics.txt'\n",
    "    with open(metrics_file, 'w') as f:\n",
    "        f.write(\"Epoch,Time(s),D_Loss,G_Loss,FID_Score\\n\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STARTING CGAN TRAINING - {num_epochs} EPOCHS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    for epoch in range(starting_epoch, num_epochs + 1):\n",
    "        epoch_start = time.time()\n",
    "        epoch_d_loss = 0\n",
    "        epoch_g_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for i, (imgs, labels) in enumerate(dataloader):\n",
    "            batch_size = imgs.size(0)\n",
    "            real_imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            real_labels = torch.ones(batch_size, 1).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "            \n",
    "            # Train Discriminator but skip training it every 3 epochs\n",
    "\n",
    "            if epoch <= 5 or i % 2 == 0:\n",
    "                optimizer_D.zero_grad()\n",
    "                real_loss = criterion(discriminator(real_imgs, labels), real_labels)\n",
    "                \n",
    "                z = torch.randn(batch_size, latent_dim).to(device)\n",
    "                fake_imgs = generator(z, labels)\n",
    "                fake_loss = criterion(discriminator(fake_imgs.detach(), labels), fake_labels)\n",
    "                \n",
    "                gp = compute_gradient_penalty(discriminator, real_imgs, fake_imgs, labels)\n",
    "                d_loss = (real_loss + fake_loss) / 2 + 5 * gp\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "            else:\n",
    "                d_loss = torch.tensor(0.0)\n",
    "\n",
    "            # Train G twice\n",
    "            for _ in range(2):\n",
    "                optimizer_G.zero_grad()\n",
    "                z = torch.randn(batch_size, latent_dim).to(device)\n",
    "                gen_imgs = generator(z, labels)\n",
    "                g_loss = criterion(discriminator(gen_imgs, labels), real_labels)\n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "            \n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_d_loss = epoch_d_loss / num_batches\n",
    "        avg_g_loss = epoch_g_loss / num_batches\n",
    "        \n",
    "        # Calculate FID every 2 epochs\n",
    "        fid_score = 0.0\n",
    "        if epoch % 2 == 0:\n",
    "            with torch.no_grad():\n",
    "                real_batch = next(iter(dataloader))[0][:128].to(device)\n",
    "                z = torch.randn(128, latent_dim).to(device)\n",
    "                sample_labels = torch.full((128,), minority_class_idx, dtype=torch.long).to(device)\n",
    "                fake_batch = generator(z, sample_labels)\n",
    "                fid_score = calculate_fid(real_batch, fake_batch, device)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        print(f\"Epoch {epoch} | Time: {epoch_time:.2f}s\")\n",
    "        print(f\"  D_Loss: {avg_d_loss:.6f} | G_Loss: {avg_g_loss:.6f}\")\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"  FID Score: {fid_score:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        with open(metrics_file, 'a') as f:\n",
    "            f.write(f\"{epoch},{epoch_time:.2f},{avg_d_loss:.6f},{avg_g_loss:.6f},{fid_score:.4f}\\n\")\n",
    "        \n",
    "        \n",
    "        save_sample_images(generator, epoch, latent_dim, save_path, labels=minority_class_idx)\n",
    "        \n",
    "        if epoch > 20 and epoch % 4 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'generator_state_dict': generator.state_dict(),\n",
    "                'discriminator_state_dict': discriminator.state_dict(),\n",
    "                'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "                'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "            }, f\"{model_path}/model_epoch_{epoch}.pt\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CGAN TRAINING COMPLETE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18d2bb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e3a31e",
   "metadata": {},
   "source": [
    "**Training Vanilla GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd8a214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "586b8e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla Generator parameters: 1,489,424\n",
      "Vanilla Discriminator parameters: 1,460,225\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "vanilla_gen = VanillaGenerator(latent_dim=latent_dim, img_size=28).to(device)\n",
    "vanilla_disc = VanillaDiscriminator(img_size=28).to(device)\n",
    "vanilla_gen.apply(weights_init)\n",
    "vanilla_disc.apply(weights_init)\n",
    "\n",
    "print(f\"Vanilla Generator parameters: {sum(p.numel() for p in vanilla_gen.parameters()):,}\")\n",
    "print(f\"Vanilla Discriminator parameters: {sum(p.numel() for p in vanilla_disc.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e67aac7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING VANILLA GAN TRAINING - 120 EPOCHS\n",
      "================================================================================\n",
      "\n",
      "Epoch 1 | Time: 2.82s\n",
      "  D_Loss: 5.264101 | G_Loss: 0.560085\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_16108\\3088281783.py:32: DeprecationWarning: The `disp` argument is deprecated and will be removed in SciPy 1.18.0.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n",
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_16108\\3088281783.py:32: LinAlgWarning: Matrix is singular. The result might be inaccurate or the array might not have a square root.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Time: 12.73s\n",
      "  D_Loss: 4.642878 | G_Loss: 0.859338\n",
      "  FID Score: 518.0356\n",
      "\n",
      "Epoch 3 | Time: 1.63s\n",
      "  D_Loss: 4.456237 | G_Loss: 0.823284\n",
      "\n",
      "Epoch 4 | Time: 16.53s\n",
      "  D_Loss: 4.525640 | G_Loss: 0.729868\n",
      "  FID Score: 463.1566\n",
      "\n",
      "Epoch 5 | Time: 1.53s\n",
      "  D_Loss: 4.362242 | G_Loss: 0.765675\n",
      "\n",
      "Epoch 6 | Time: 15.25s\n",
      "  D_Loss: 4.093177 | G_Loss: 0.884674\n",
      "  FID Score: 487.8307\n",
      "\n",
      "Epoch 7 | Time: 1.68s\n",
      "  D_Loss: 3.741555 | G_Loss: 1.000810\n",
      "\n",
      "Epoch 8 | Time: 14.44s\n",
      "  D_Loss: 3.408796 | G_Loss: 0.904279\n",
      "  FID Score: 422.4494\n",
      "\n",
      "Epoch 9 | Time: 2.23s\n",
      "  D_Loss: 2.909197 | G_Loss: 0.811868\n",
      "\n",
      "Epoch 10 | Time: 14.21s\n",
      "  D_Loss: 2.651665 | G_Loss: 0.747097\n",
      "  FID Score: 385.0221\n",
      "\n",
      "Epoch 11 | Time: 1.33s\n",
      "  D_Loss: 1.379952 | G_Loss: 0.582346\n",
      "\n",
      "Epoch 12 | Time: 15.85s\n",
      "  D_Loss: 1.306065 | G_Loss: 0.531220\n",
      "  FID Score: 361.5755\n",
      "\n",
      "Epoch 13 | Time: 1.36s\n",
      "  D_Loss: 1.338386 | G_Loss: 0.511708\n",
      "\n",
      "Epoch 14 | Time: 11.50s\n",
      "  D_Loss: 1.247839 | G_Loss: 0.507876\n",
      "  FID Score: 386.5652\n",
      "\n",
      "Epoch 15 | Time: 1.27s\n",
      "  D_Loss: 1.147187 | G_Loss: 0.507536\n",
      "\n",
      "Epoch 16 | Time: 11.54s\n",
      "  D_Loss: 1.092471 | G_Loss: 0.504179\n",
      "  FID Score: 381.7736\n",
      "\n",
      "Epoch 17 | Time: 1.21s\n",
      "  D_Loss: 1.009401 | G_Loss: 0.522966\n",
      "\n",
      "Epoch 18 | Time: 15.07s\n",
      "  D_Loss: 0.939940 | G_Loss: 0.522551\n",
      "  FID Score: 398.0688\n",
      "\n",
      "Epoch 19 | Time: 1.31s\n",
      "  D_Loss: 0.848434 | G_Loss: 0.543372\n",
      "\n",
      "Epoch 20 | Time: 10.95s\n",
      "  D_Loss: 0.757973 | G_Loss: 0.578638\n",
      "  FID Score: 386.5357\n",
      "\n",
      "Epoch 21 | Time: 1.19s\n",
      "  D_Loss: 0.685723 | G_Loss: 0.597568\n",
      "\n",
      "Epoch 22 | Time: 14.72s\n",
      "  D_Loss: 0.641530 | G_Loss: 0.620539\n",
      "  FID Score: 388.1740\n",
      "\n",
      "Epoch 23 | Time: 1.21s\n",
      "  D_Loss: 0.638438 | G_Loss: 0.663912\n",
      "\n",
      "Epoch 24 | Time: 12.88s\n",
      "  D_Loss: 0.560344 | G_Loss: 0.673816\n",
      "  FID Score: 363.2019\n",
      "\n",
      "Epoch 25 | Time: 1.22s\n",
      "  D_Loss: 0.541769 | G_Loss: 0.700918\n",
      "\n",
      "Epoch 26 | Time: 14.72s\n",
      "  D_Loss: 0.519522 | G_Loss: 0.703315\n",
      "  FID Score: 386.8247\n",
      "\n",
      "Epoch 27 | Time: 1.21s\n",
      "  D_Loss: 0.499907 | G_Loss: 0.709842\n",
      "\n",
      "Epoch 28 | Time: 15.17s\n",
      "  D_Loss: 0.533073 | G_Loss: 0.745419\n",
      "  FID Score: 381.9083\n",
      "\n",
      "Epoch 29 | Time: 1.26s\n",
      "  D_Loss: 0.503630 | G_Loss: 0.732297\n",
      "\n",
      "Epoch 30 | Time: 14.38s\n",
      "  D_Loss: 0.479636 | G_Loss: 0.721804\n",
      "  FID Score: 380.1671\n",
      "\n",
      "Epoch 31 | Time: 1.13s\n",
      "  D_Loss: 0.470730 | G_Loss: 0.736254\n",
      "\n",
      "Epoch 32 | Time: 11.60s\n",
      "  D_Loss: 0.463476 | G_Loss: 0.742376\n",
      "  FID Score: 357.4488\n",
      "\n",
      "Epoch 33 | Time: 1.16s\n",
      "  D_Loss: 0.486036 | G_Loss: 0.753229\n",
      "\n",
      "Epoch 34 | Time: 12.96s\n",
      "  D_Loss: 0.486282 | G_Loss: 0.724259\n",
      "  FID Score: 303.9993\n",
      "\n",
      "Epoch 35 | Time: 1.18s\n",
      "  D_Loss: 0.491896 | G_Loss: 0.720141\n",
      "\n",
      "Epoch 36 | Time: 14.37s\n",
      "  D_Loss: 0.483651 | G_Loss: 0.732066\n",
      "  FID Score: 298.4996\n",
      "\n",
      "Epoch 37 | Time: 1.17s\n",
      "  D_Loss: 0.597086 | G_Loss: 0.772762\n",
      "\n",
      "Epoch 38 | Time: 14.36s\n",
      "  D_Loss: 0.456738 | G_Loss: 0.739369\n",
      "  FID Score: 284.4139\n",
      "\n",
      "Epoch 39 | Time: 1.15s\n",
      "  D_Loss: 0.460640 | G_Loss: 0.720396\n",
      "\n",
      "Epoch 40 | Time: 14.63s\n",
      "  D_Loss: 0.469620 | G_Loss: 0.729334\n",
      "  FID Score: 301.1806\n",
      "\n",
      "Epoch 41 | Time: 1.17s\n",
      "  D_Loss: 0.479455 | G_Loss: 0.692099\n",
      "\n",
      "Epoch 42 | Time: 14.32s\n",
      "  D_Loss: 0.549026 | G_Loss: 0.604561\n",
      "  FID Score: 312.9398\n",
      "\n",
      "Epoch 43 | Time: 1.31s\n",
      "  D_Loss: 0.517416 | G_Loss: 0.602885\n",
      "\n",
      "Epoch 44 | Time: 12.33s\n",
      "  D_Loss: 0.500335 | G_Loss: 0.643188\n",
      "  FID Score: 331.8303\n",
      "\n",
      "Epoch 45 | Time: 1.40s\n",
      "  D_Loss: 0.468088 | G_Loss: 0.667529\n",
      "\n",
      "Epoch 46 | Time: 11.47s\n",
      "  D_Loss: 0.433991 | G_Loss: 0.715671\n",
      "  FID Score: 335.7032\n",
      "\n",
      "Epoch 47 | Time: 0.99s\n",
      "  D_Loss: 0.415814 | G_Loss: 0.732966\n",
      "\n",
      "Epoch 48 | Time: 15.38s\n",
      "  D_Loss: 0.427890 | G_Loss: 0.730203\n",
      "  FID Score: 314.9553\n",
      "\n",
      "Epoch 49 | Time: 1.17s\n",
      "  D_Loss: 0.413249 | G_Loss: 0.715595\n",
      "\n",
      "Epoch 50 | Time: 14.50s\n",
      "  D_Loss: 0.455349 | G_Loss: 0.641052\n",
      "  FID Score: 354.6238\n",
      "\n",
      "Epoch 51 | Time: 1.16s\n",
      "  D_Loss: 0.464805 | G_Loss: 0.668785\n",
      "\n",
      "Epoch 52 | Time: 14.52s\n",
      "  D_Loss: 0.439568 | G_Loss: 0.661480\n",
      "  FID Score: 324.2951\n",
      "\n",
      "Epoch 53 | Time: 1.19s\n",
      "  D_Loss: 0.433982 | G_Loss: 0.654666\n",
      "\n",
      "Epoch 54 | Time: 14.12s\n",
      "  D_Loss: 0.448152 | G_Loss: 0.633925\n",
      "  FID Score: 353.3447\n",
      "\n",
      "Epoch 55 | Time: 1.22s\n",
      "  D_Loss: 0.445913 | G_Loss: 0.647260\n",
      "\n",
      "Epoch 56 | Time: 14.88s\n",
      "  D_Loss: 0.447941 | G_Loss: 0.665042\n",
      "  FID Score: 341.5882\n",
      "\n",
      "Epoch 57 | Time: 1.15s\n",
      "  D_Loss: 0.424548 | G_Loss: 0.675541\n",
      "\n",
      "Epoch 58 | Time: 13.78s\n",
      "  D_Loss: 0.428355 | G_Loss: 0.695653\n",
      "  FID Score: 322.6271\n",
      "\n",
      "Epoch 59 | Time: 1.15s\n",
      "  D_Loss: 0.434350 | G_Loss: 0.708019\n",
      "\n",
      "Epoch 60 | Time: 14.60s\n",
      "  D_Loss: 0.430356 | G_Loss: 0.708123\n",
      "  FID Score: 326.0602\n",
      "\n",
      "Epoch 61 | Time: 1.13s\n",
      "  D_Loss: 0.419948 | G_Loss: 0.699523\n",
      "\n",
      "Epoch 62 | Time: 14.62s\n",
      "  D_Loss: 0.445589 | G_Loss: 0.716177\n",
      "  FID Score: 300.0274\n",
      "\n",
      "Epoch 63 | Time: 1.35s\n",
      "  D_Loss: 0.425351 | G_Loss: 0.696756\n",
      "\n",
      "Epoch 64 | Time: 15.32s\n",
      "  D_Loss: 0.427728 | G_Loss: 0.701295\n",
      "  FID Score: 323.4217\n",
      "\n",
      "Epoch 65 | Time: 1.29s\n",
      "  D_Loss: 0.442863 | G_Loss: 0.709923\n",
      "\n",
      "Epoch 66 | Time: 15.26s\n",
      "  D_Loss: 0.681802 | G_Loss: 0.913152\n",
      "  FID Score: 337.1743\n",
      "\n",
      "Epoch 67 | Time: 1.36s\n",
      "  D_Loss: 0.437974 | G_Loss: 0.702368\n",
      "\n",
      "Epoch 68 | Time: 11.86s\n",
      "  D_Loss: 0.432722 | G_Loss: 0.721092\n",
      "  FID Score: 336.0681\n",
      "\n",
      "Epoch 69 | Time: 1.22s\n",
      "  D_Loss: 0.422674 | G_Loss: 0.703471\n",
      "\n",
      "Epoch 70 | Time: 15.28s\n",
      "  D_Loss: 0.425604 | G_Loss: 0.707107\n",
      "  FID Score: 301.6458\n",
      "\n",
      "Epoch 71 | Time: 1.24s\n",
      "  D_Loss: 0.426847 | G_Loss: 0.699394\n",
      "\n",
      "Epoch 72 | Time: 11.73s\n",
      "  D_Loss: 0.420624 | G_Loss: 0.692335\n",
      "  FID Score: 275.7226\n",
      "\n",
      "Epoch 73 | Time: 1.20s\n",
      "  D_Loss: 0.424489 | G_Loss: 0.712693\n",
      "\n",
      "Epoch 74 | Time: 14.86s\n",
      "  D_Loss: 0.416995 | G_Loss: 0.687517\n",
      "  FID Score: 305.4731\n",
      "\n",
      "Epoch 75 | Time: 1.22s\n",
      "  D_Loss: 0.421763 | G_Loss: 0.687288\n",
      "\n",
      "Epoch 76 | Time: 14.27s\n",
      "  D_Loss: 0.428708 | G_Loss: 0.685265\n",
      "  FID Score: 278.7916\n",
      "\n",
      "Epoch 77 | Time: 1.19s\n",
      "  D_Loss: 0.403814 | G_Loss: 0.701039\n",
      "\n",
      "Epoch 78 | Time: 14.32s\n",
      "  D_Loss: 0.406670 | G_Loss: 0.696798\n",
      "  FID Score: 280.9976\n",
      "\n",
      "Epoch 79 | Time: 1.19s\n",
      "  D_Loss: 0.401808 | G_Loss: 0.705691\n",
      "\n",
      "Epoch 80 | Time: 11.70s\n",
      "  D_Loss: 0.403401 | G_Loss: 0.702071\n",
      "  FID Score: 302.3747\n",
      "\n",
      "Epoch 81 | Time: 1.25s\n",
      "  D_Loss: 0.410425 | G_Loss: 0.699661\n",
      "\n",
      "Epoch 82 | Time: 16.30s\n",
      "  D_Loss: 0.417306 | G_Loss: 0.690429\n",
      "  FID Score: 253.3211\n",
      "\n",
      "Epoch 83 | Time: 1.25s\n",
      "  D_Loss: 0.415652 | G_Loss: 0.688704\n",
      "\n",
      "Epoch 84 | Time: 12.23s\n",
      "  D_Loss: 0.660617 | G_Loss: 0.840241\n",
      "  FID Score: 279.4628\n",
      "\n",
      "Epoch 85 | Time: 1.18s\n",
      "  D_Loss: 0.416597 | G_Loss: 0.733461\n",
      "\n",
      "Epoch 86 | Time: 14.41s\n",
      "  D_Loss: 0.417313 | G_Loss: 0.704347\n",
      "  FID Score: 280.0106\n",
      "\n",
      "Epoch 87 | Time: 1.15s\n",
      "  D_Loss: 0.415493 | G_Loss: 0.710409\n",
      "\n",
      "Epoch 88 | Time: 14.88s\n",
      "  D_Loss: 0.407868 | G_Loss: 0.692033\n",
      "  FID Score: 303.1818\n",
      "\n",
      "Epoch 89 | Time: 1.14s\n",
      "  D_Loss: 0.411748 | G_Loss: 0.685408\n",
      "\n",
      "Epoch 90 | Time: 15.61s\n",
      "  D_Loss: 0.403752 | G_Loss: 0.692881\n",
      "  FID Score: 291.9713\n",
      "\n",
      "Epoch 91 | Time: 1.21s\n",
      "  D_Loss: 0.407100 | G_Loss: 0.690044\n",
      "\n",
      "Epoch 92 | Time: 14.93s\n",
      "  D_Loss: 0.403991 | G_Loss: 0.686378\n",
      "  FID Score: 325.6119\n",
      "\n",
      "Epoch 93 | Time: 1.24s\n",
      "  D_Loss: 0.393120 | G_Loss: 0.687439\n",
      "\n",
      "Epoch 94 | Time: 11.46s\n",
      "  D_Loss: 0.395329 | G_Loss: 0.691970\n",
      "  FID Score: 338.7717\n",
      "\n",
      "Epoch 95 | Time: 1.52s\n",
      "  D_Loss: 0.396311 | G_Loss: 0.694184\n",
      "\n",
      "Epoch 96 | Time: 12.61s\n",
      "  D_Loss: 0.392187 | G_Loss: 0.677215\n",
      "  FID Score: 282.5033\n",
      "\n",
      "Epoch 97 | Time: 1.32s\n",
      "  D_Loss: 0.409281 | G_Loss: 0.699657\n",
      "\n",
      "Epoch 98 | Time: 15.42s\n",
      "  D_Loss: 0.400041 | G_Loss: 0.702629\n",
      "  FID Score: 333.5748\n",
      "\n",
      "Epoch 99 | Time: 1.36s\n",
      "  D_Loss: 0.392910 | G_Loss: 0.694403\n",
      "\n",
      "Epoch 100 | Time: 11.33s\n",
      "  D_Loss: 0.403385 | G_Loss: 0.696603\n",
      "  FID Score: 297.5256\n",
      "\n",
      "Epoch 101 | Time: 1.16s\n",
      "  D_Loss: 0.389241 | G_Loss: 0.695981\n",
      "\n",
      "Epoch 102 | Time: 14.82s\n",
      "  D_Loss: 0.396040 | G_Loss: 0.676836\n",
      "  FID Score: 301.5895\n",
      "\n",
      "Epoch 103 | Time: 1.28s\n",
      "  D_Loss: 0.416546 | G_Loss: 0.675283\n",
      "\n",
      "Epoch 104 | Time: 14.75s\n",
      "  D_Loss: 9.632705 | G_Loss: 36.217369\n",
      "  FID Score: 312.3712\n",
      "\n",
      "Epoch 105 | Time: 1.24s\n",
      "  D_Loss: 27.500000 | G_Loss: 100.000000\n",
      "\n",
      "Epoch 106 | Time: 14.79s\n",
      "  D_Loss: 27.500000 | G_Loss: 100.000000\n",
      "  FID Score: 310.2030\n",
      "\n",
      "Epoch 107 | Time: 1.23s\n",
      "  D_Loss: 27.500000 | G_Loss: 100.000000\n",
      "\n",
      "Epoch 108 | Time: 14.89s\n",
      "  D_Loss: 27.500000 | G_Loss: 100.000000\n",
      "  FID Score: 325.5127\n",
      "\n",
      "Epoch 109 | Time: 1.15s\n",
      "  D_Loss: 27.500000 | G_Loss: 100.000000\n",
      "\n",
      "Epoch 110 | Time: 15.46s\n",
      "  D_Loss: 27.500000 | G_Loss: 100.000000\n",
      "  FID Score: 302.0178\n",
      "\n",
      "Epoch 111 | Time: 1.26s\n",
      "  D_Loss: 27.500000 | G_Loss: 100.000000\n",
      "\n",
      "Epoch 112 | Time: 13.16s\n",
      "  D_Loss: 27.500000 | G_Loss: 100.000000\n",
      "  FID Score: 309.1310\n",
      "\n",
      "Epoch 113 | Time: 1.14s\n",
      "  D_Loss: 27.500000 | G_Loss: 100.000000\n",
      "\n",
      "Epoch 114 | Time: 14.76s\n",
      "  D_Loss: 27.500000 | G_Loss: 100.000000\n",
      "  FID Score: 303.3891\n",
      "\n",
      "Epoch 115 | Time: 1.24s\n",
      "  D_Loss: 27.500000 | G_Loss: 100.000000\n",
      "\n",
      "Epoch 116 | Time: 14.53s\n",
      "  D_Loss: 27.500000 | G_Loss: 100.000000\n",
      "  FID Score: 318.4775\n",
      "\n",
      "Epoch 117 | Time: 1.14s\n",
      "  D_Loss: 27.500000 | G_Loss: 100.000000\n",
      "\n",
      "Epoch 118 | Time: 13.95s\n",
      "  D_Loss: 27.500000 | G_Loss: 100.000000\n",
      "  FID Score: 319.2204\n",
      "\n",
      "Epoch 119 | Time: 1.17s\n",
      "  D_Loss: 27.500000 | G_Loss: 100.000000\n",
      "\n",
      "Epoch 120 | Time: 14.65s\n",
      "  D_Loss: 27.500000 | G_Loss: 100.000000\n",
      "  FID Score: 315.2143\n",
      "\n",
      "\n",
      "================================================================================\n",
      "VANILLA GAN TRAINING COMPLETE\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Vanilla GAN\n",
    "vanilla_gen, vanilla_disc = train_vanilla_gan(\n",
    "    vanilla_gen, \n",
    "    vanilla_disc, \n",
    "    minority_loader, \n",
    "    num_epochs=120,\n",
    "    latent_dim=latent_dim,\n",
    "    save_path='generated_images/vanilla_gan',\n",
    "    model_path='models/vanilla_gan'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f91818",
   "metadata": {},
   "source": [
    "The best Epoch is 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4953e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "del vanilla_gen, vanilla_disc\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b744f4f3",
   "metadata": {},
   "source": [
    "**Training DCGAN GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8a147a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DCGAN Generator parameters: 766,017\n",
      "DCGAN Discriminator parameters: 138,561\n"
     ]
    }
   ],
   "source": [
    "# Initialize DCGAN\n",
    "dcgan_gen = DCGANGenerator(latent_dim=latent_dim, img_channels=1).to(device)\n",
    "dcgan_disc = DCGANDiscriminator().to(device)\n",
    "\n",
    "dcgan_gen.apply(weights_init)\n",
    "dcgan_disc.apply(weights_init)\n",
    "\n",
    "print(f\"\\nDCGAN Generator parameters: {sum(p.numel() for p in dcgan_gen.parameters()):,}\")\n",
    "print(f\"DCGAN Discriminator parameters: {sum(p.numel() for p in dcgan_disc.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb58553b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING DCGAN TRAINING - 90 EPOCHS\n",
      "================================================================================\n",
      "\n",
      "Epoch 1 | Time: 1.64s\n",
      "  D_Loss: 2.260379 | G_Loss: 0.920222\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_16108\\3088281783.py:32: DeprecationWarning: The `disp` argument is deprecated and will be removed in SciPy 1.18.0.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Time: 12.26s\n",
      "  D_Loss: 1.931814 | G_Loss: 1.500543\n",
      "  FID Score: 431.7587\n",
      "\n",
      "Epoch 3 | Time: 1.35s\n",
      "  D_Loss: 1.810199 | G_Loss: 1.756070\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_16108\\3088281783.py:32: LinAlgWarning: Matrix is singular. The result might be inaccurate or the array might not have a square root.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Time: 14.95s\n",
      "  D_Loss: 1.800336 | G_Loss: 1.370924\n",
      "  FID Score: 445.4994\n",
      "\n",
      "Epoch 5 | Time: 1.28s\n",
      "  D_Loss: 1.716866 | G_Loss: 1.184177\n",
      "\n",
      "Epoch 6 | Time: 15.31s\n",
      "  D_Loss: 1.656825 | G_Loss: 0.870761\n",
      "  FID Score: 369.2838\n",
      "\n",
      "Epoch 7 | Time: 1.32s\n",
      "  D_Loss: 1.643644 | G_Loss: 0.917189\n",
      "\n",
      "Epoch 8 | Time: 11.68s\n",
      "  D_Loss: 1.522435 | G_Loss: 1.032365\n",
      "  FID Score: 324.9901\n",
      "\n",
      "Epoch 9 | Time: 1.32s\n",
      "  D_Loss: 1.596839 | G_Loss: 0.778700\n",
      "\n",
      "Epoch 10 | Time: 15.24s\n",
      "  D_Loss: 1.677904 | G_Loss: 0.732065\n",
      "  FID Score: 392.4905\n",
      "\n",
      "Epoch 11 | Time: 0.90s\n",
      "  D_Loss: 0.566141 | G_Loss: 0.771075\n",
      "\n",
      "Epoch 12 | Time: 14.17s\n",
      "  D_Loss: 0.617097 | G_Loss: 0.601899\n",
      "  FID Score: 308.6601\n",
      "\n",
      "Epoch 13 | Time: 0.99s\n",
      "  D_Loss: 0.619508 | G_Loss: 0.652254\n",
      "\n",
      "Epoch 14 | Time: 12.08s\n",
      "  D_Loss: 0.582077 | G_Loss: 0.754117\n",
      "  FID Score: 282.4316\n",
      "\n",
      "Epoch 15 | Time: 1.06s\n",
      "  D_Loss: 0.565006 | G_Loss: 0.751214\n",
      "\n",
      "Epoch 16 | Time: 10.74s\n",
      "  D_Loss: 0.570861 | G_Loss: 0.663671\n",
      "  FID Score: 251.4420\n",
      "\n",
      "Epoch 17 | Time: 1.04s\n",
      "  D_Loss: 0.591841 | G_Loss: 0.582566\n",
      "\n",
      "Epoch 18 | Time: 14.53s\n",
      "  D_Loss: 0.571350 | G_Loss: 0.641367\n",
      "  FID Score: 272.1896\n",
      "\n",
      "Epoch 19 | Time: 0.96s\n",
      "  D_Loss: 0.563715 | G_Loss: 0.663706\n",
      "\n",
      "Epoch 20 | Time: 11.40s\n",
      "  D_Loss: 0.570886 | G_Loss: 0.639122\n",
      "  FID Score: 291.1871\n",
      "\n",
      "Epoch 21 | Time: 0.95s\n",
      "  D_Loss: 0.541081 | G_Loss: 0.693208\n",
      "\n",
      "Epoch 22 | Time: 14.76s\n",
      "  D_Loss: 0.530524 | G_Loss: 0.664743\n",
      "  FID Score: 262.1847\n",
      "\n",
      "Epoch 23 | Time: 0.92s\n",
      "  D_Loss: 0.531257 | G_Loss: 0.626026\n",
      "\n",
      "Epoch 24 | Time: 14.16s\n",
      "  D_Loss: 0.532268 | G_Loss: 0.600484\n",
      "  FID Score: 245.3549\n",
      "\n",
      "Epoch 25 | Time: 0.86s\n",
      "  D_Loss: 0.537297 | G_Loss: 0.596257\n",
      "\n",
      "Epoch 26 | Time: 15.37s\n",
      "  D_Loss: 0.528465 | G_Loss: 0.609308\n",
      "  FID Score: 242.5164\n",
      "\n",
      "Epoch 27 | Time: 0.91s\n",
      "  D_Loss: 0.515495 | G_Loss: 0.638882\n",
      "\n",
      "Epoch 28 | Time: 13.85s\n",
      "  D_Loss: 0.504267 | G_Loss: 0.639560\n",
      "  FID Score: 233.2346\n",
      "\n",
      "Epoch 29 | Time: 0.87s\n",
      "  D_Loss: 0.500403 | G_Loss: 0.625494\n",
      "\n",
      "Epoch 30 | Time: 14.86s\n",
      "  D_Loss: 0.496841 | G_Loss: 0.608148\n",
      "  FID Score: 226.6485\n",
      "\n",
      "Epoch 31 | Time: 0.89s\n",
      "  D_Loss: 0.494906 | G_Loss: 0.607767\n",
      "\n",
      "Epoch 32 | Time: 15.10s\n",
      "  D_Loss: 0.492337 | G_Loss: 0.617018\n",
      "  FID Score: 239.5656\n",
      "\n",
      "Epoch 33 | Time: 0.86s\n",
      "  D_Loss: 0.483247 | G_Loss: 0.640484\n",
      "\n",
      "Epoch 34 | Time: 14.22s\n",
      "  D_Loss: 0.471870 | G_Loss: 0.668681\n",
      "  FID Score: 238.0207\n",
      "\n",
      "Epoch 35 | Time: 0.99s\n",
      "  D_Loss: 0.469203 | G_Loss: 0.662163\n",
      "\n",
      "Epoch 36 | Time: 14.86s\n",
      "  D_Loss: 0.463971 | G_Loss: 0.653896\n",
      "  FID Score: 221.6058\n",
      "\n",
      "Epoch 37 | Time: 0.87s\n",
      "  D_Loss: 0.466584 | G_Loss: 0.649952\n",
      "\n",
      "Epoch 38 | Time: 14.24s\n",
      "  D_Loss: 0.460731 | G_Loss: 0.645675\n",
      "  FID Score: 217.1119\n",
      "\n",
      "Epoch 39 | Time: 0.86s\n",
      "  D_Loss: 0.454783 | G_Loss: 0.647079\n",
      "\n",
      "Epoch 40 | Time: 13.38s\n",
      "  D_Loss: 0.453844 | G_Loss: 0.649134\n",
      "  FID Score: 223.9237\n",
      "\n",
      "Epoch 41 | Time: 0.89s\n",
      "  D_Loss: 0.446469 | G_Loss: 0.659985\n",
      "\n",
      "Epoch 42 | Time: 13.76s\n",
      "  D_Loss: 0.439969 | G_Loss: 0.655202\n",
      "  FID Score: 221.8011\n",
      "\n",
      "Epoch 43 | Time: 0.87s\n",
      "  D_Loss: 0.436478 | G_Loss: 0.665147\n",
      "\n",
      "Epoch 44 | Time: 14.29s\n",
      "  D_Loss: 0.434410 | G_Loss: 0.659521\n",
      "  FID Score: 222.0410\n",
      "\n",
      "Epoch 45 | Time: 0.87s\n",
      "  D_Loss: 0.430320 | G_Loss: 0.657351\n",
      "\n",
      "Epoch 46 | Time: 10.12s\n",
      "  D_Loss: 0.426811 | G_Loss: 0.658813\n",
      "  FID Score: 199.6827\n",
      "\n",
      "Epoch 47 | Time: 0.95s\n",
      "  D_Loss: 0.423141 | G_Loss: 0.661754\n",
      "\n",
      "Epoch 48 | Time: 12.36s\n",
      "  D_Loss: 0.418169 | G_Loss: 0.659947\n",
      "  FID Score: 219.0302\n",
      "\n",
      "Epoch 49 | Time: 1.05s\n",
      "  D_Loss: 0.409595 | G_Loss: 0.666316\n",
      "\n",
      "Epoch 50 | Time: 11.33s\n",
      "  D_Loss: 0.406823 | G_Loss: 0.664417\n",
      "  FID Score: 221.1822\n",
      "\n",
      "Epoch 51 | Time: 0.99s\n",
      "  D_Loss: 0.402403 | G_Loss: 0.662697\n",
      "\n",
      "Epoch 52 | Time: 13.52s\n",
      "  D_Loss: 0.400156 | G_Loss: 0.661822\n",
      "  FID Score: 205.6565\n",
      "\n",
      "Epoch 53 | Time: 1.12s\n",
      "  D_Loss: 0.395634 | G_Loss: 0.664042\n",
      "\n",
      "Epoch 54 | Time: 14.77s\n",
      "  D_Loss: 0.393833 | G_Loss: 0.662353\n",
      "  FID Score: 216.2580\n",
      "\n",
      "Epoch 55 | Time: 0.96s\n",
      "  D_Loss: 0.392513 | G_Loss: 0.663562\n",
      "\n",
      "Epoch 56 | Time: 14.05s\n",
      "  D_Loss: 0.391289 | G_Loss: 0.665156\n",
      "  FID Score: 204.3295\n",
      "\n",
      "Epoch 57 | Time: 1.01s\n",
      "  D_Loss: 0.386302 | G_Loss: 0.663120\n",
      "\n",
      "Epoch 58 | Time: 17.11s\n",
      "  D_Loss: 0.386663 | G_Loss: 0.663762\n",
      "  FID Score: 206.8603\n",
      "\n",
      "Epoch 59 | Time: 0.89s\n",
      "  D_Loss: 0.374302 | G_Loss: 0.666986\n",
      "\n",
      "Epoch 60 | Time: 14.55s\n",
      "  D_Loss: 0.375008 | G_Loss: 0.666283\n",
      "  FID Score: 197.8835\n",
      "\n",
      "Epoch 61 | Time: 0.89s\n",
      "  D_Loss: 0.374635 | G_Loss: 0.662599\n",
      "\n",
      "Epoch 62 | Time: 13.73s\n",
      "  D_Loss: 0.372584 | G_Loss: 0.663255\n",
      "  FID Score: 197.1357\n",
      "\n",
      "Epoch 63 | Time: 0.94s\n",
      "  D_Loss: 0.370940 | G_Loss: 0.662096\n",
      "\n",
      "Epoch 64 | Time: 14.19s\n",
      "  D_Loss: 0.366122 | G_Loss: 0.663287\n",
      "  FID Score: 191.2410\n",
      "\n",
      "Epoch 65 | Time: 0.90s\n",
      "  D_Loss: 0.365193 | G_Loss: 0.661183\n",
      "\n",
      "Epoch 66 | Time: 14.05s\n",
      "  D_Loss: 0.365249 | G_Loss: 0.664232\n",
      "  FID Score: 181.4683\n",
      "\n",
      "Epoch 67 | Time: 0.94s\n",
      "  D_Loss: 0.362199 | G_Loss: 0.664295\n",
      "\n",
      "Epoch 68 | Time: 14.30s\n",
      "  D_Loss: 0.356948 | G_Loss: 0.665430\n",
      "  FID Score: 187.5695\n",
      "\n",
      "Epoch 69 | Time: 0.99s\n",
      "  D_Loss: 0.357777 | G_Loss: 0.666596\n",
      "\n",
      "Epoch 70 | Time: 14.82s\n",
      "  D_Loss: 0.359156 | G_Loss: 0.660799\n",
      "  FID Score: 185.1676\n",
      "\n",
      "Epoch 71 | Time: 0.92s\n",
      "  D_Loss: 0.357529 | G_Loss: 0.660765\n",
      "\n",
      "Epoch 72 | Time: 14.03s\n",
      "  D_Loss: 0.353240 | G_Loss: 0.665633\n",
      "  FID Score: 188.9735\n",
      "\n",
      "Epoch 73 | Time: 0.93s\n",
      "  D_Loss: 0.355083 | G_Loss: 0.670253\n",
      "\n",
      "Epoch 74 | Time: 12.20s\n",
      "  D_Loss: 0.347362 | G_Loss: 0.663461\n",
      "  FID Score: 170.3216\n",
      "\n",
      "Epoch 75 | Time: 0.89s\n",
      "  D_Loss: 0.348736 | G_Loss: 0.666678\n",
      "\n",
      "Epoch 76 | Time: 14.16s\n",
      "  D_Loss: 0.349007 | G_Loss: 0.666363\n",
      "  FID Score: 176.5366\n",
      "\n",
      "Epoch 77 | Time: 0.88s\n",
      "  D_Loss: 0.344827 | G_Loss: 0.664836\n",
      "\n",
      "Epoch 78 | Time: 13.75s\n",
      "  D_Loss: 0.343554 | G_Loss: 0.665430\n",
      "  FID Score: 178.5429\n",
      "\n",
      "Epoch 79 | Time: 0.96s\n",
      "  D_Loss: 0.343393 | G_Loss: 0.665018\n",
      "\n",
      "Epoch 80 | Time: 14.07s\n",
      "  D_Loss: 0.343006 | G_Loss: 0.666760\n",
      "  FID Score: 178.2009\n",
      "\n",
      "Epoch 81 | Time: 0.89s\n",
      "  D_Loss: 0.340924 | G_Loss: 0.663061\n",
      "\n",
      "Epoch 82 | Time: 13.67s\n",
      "  D_Loss: 0.336761 | G_Loss: 0.663843\n",
      "  FID Score: 184.7926\n",
      "\n",
      "Epoch 83 | Time: 0.93s\n",
      "  D_Loss: 0.339951 | G_Loss: 0.661340\n",
      "\n",
      "Epoch 84 | Time: 14.19s\n",
      "  D_Loss: 0.337367 | G_Loss: 0.662823\n",
      "  FID Score: 176.9878\n",
      "\n",
      "Epoch 85 | Time: 0.92s\n",
      "  D_Loss: 0.333251 | G_Loss: 0.665504\n",
      "\n",
      "Epoch 86 | Time: 13.61s\n",
      "  D_Loss: 0.336549 | G_Loss: 0.662764\n",
      "  FID Score: 169.3603\n",
      "\n",
      "Epoch 87 | Time: 0.87s\n",
      "  D_Loss: 0.334649 | G_Loss: 0.662977\n",
      "\n",
      "Epoch 88 | Time: 14.65s\n",
      "  D_Loss: 0.328547 | G_Loss: 0.662692\n",
      "  FID Score: 179.3667\n",
      "\n",
      "Epoch 89 | Time: 0.89s\n",
      "  D_Loss: 0.334970 | G_Loss: 0.665993\n",
      "\n",
      "Epoch 90 | Time: 14.15s\n",
      "  D_Loss: 0.332040 | G_Loss: 0.665460\n",
      "  FID Score: 164.2839\n",
      "\n",
      "\n",
      "================================================================================\n",
      "DCGAN TRAINING COMPLETE\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dcgan_gen, dcgan_disc = train_dcgan(\n",
    "    dcgan_gen,\n",
    "    dcgan_disc,\n",
    "    minority_loader,\n",
    "    num_epochs=90,\n",
    "    latent_dim=latent_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "268eec5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING DCGAN TRAINING - 40 EPOCHS\n",
      "================================================================================\n",
      "\n",
      "Epoch 91 | Time: 0.92s\n",
      "  D_Loss: 0.332925 | G_Loss: 0.665576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_16108\\3088281783.py:32: DeprecationWarning: The `disp` argument is deprecated and will be removed in SciPy 1.18.0.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 | Time: 11.22s\n",
      "  D_Loss: 0.330868 | G_Loss: 0.667165\n",
      "  FID Score: 158.4287\n",
      "\n",
      "Epoch 93 | Time: 0.97s\n",
      "  D_Loss: 0.323998 | G_Loss: 0.661991\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_16108\\3088281783.py:32: LinAlgWarning: Matrix is singular. The result might be inaccurate or the array might not have a square root.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 | Time: 14.98s\n",
      "  D_Loss: 0.329644 | G_Loss: 0.669420\n",
      "  FID Score: 175.9784\n",
      "\n",
      "Epoch 95 | Time: 0.91s\n",
      "  D_Loss: 0.327549 | G_Loss: 0.666487\n",
      "\n",
      "Epoch 96 | Time: 14.00s\n",
      "  D_Loss: 0.326502 | G_Loss: 0.663914\n",
      "  FID Score: 162.7652\n",
      "\n",
      "Epoch 97 | Time: 1.01s\n",
      "  D_Loss: 0.327408 | G_Loss: 0.668782\n",
      "\n",
      "Epoch 98 | Time: 10.32s\n",
      "  D_Loss: 0.321347 | G_Loss: 0.659073\n",
      "  FID Score: 177.0736\n",
      "\n",
      "Epoch 99 | Time: 0.90s\n",
      "  D_Loss: 0.328572 | G_Loss: 0.666037\n",
      "\n",
      "Epoch 100 | Time: 15.26s\n",
      "  D_Loss: 0.322016 | G_Loss: 0.662711\n",
      "  FID Score: 172.6832\n",
      "\n",
      "Epoch 101 | Time: 0.98s\n",
      "  D_Loss: 0.320817 | G_Loss: 0.666348\n",
      "\n",
      "Epoch 102 | Time: 11.05s\n",
      "  D_Loss: 0.322077 | G_Loss: 0.667308\n",
      "  FID Score: 198.5219\n",
      "\n",
      "Epoch 103 | Time: 0.94s\n",
      "  D_Loss: 0.319539 | G_Loss: 0.665896\n",
      "\n",
      "Epoch 104 | Time: 14.89s\n",
      "  D_Loss: 0.320245 | G_Loss: 0.668212\n",
      "  FID Score: 152.3712\n",
      "\n",
      "Epoch 105 | Time: 0.86s\n",
      "  D_Loss: 0.318892 | G_Loss: 0.666660\n",
      "\n",
      "Epoch 106 | Time: 13.55s\n",
      "  D_Loss: 0.318114 | G_Loss: 0.661518\n",
      "  FID Score: 187.5616\n",
      "\n",
      "Epoch 107 | Time: 0.93s\n",
      "  D_Loss: 0.316960 | G_Loss: 0.676150\n",
      "\n",
      "Epoch 108 | Time: 14.28s\n",
      "  D_Loss: 0.314043 | G_Loss: 0.668549\n",
      "  FID Score: 170.7880\n",
      "\n",
      "Epoch 109 | Time: 0.91s\n",
      "  D_Loss: 0.311372 | G_Loss: 0.662581\n",
      "\n",
      "Epoch 110 | Time: 14.06s\n",
      "  D_Loss: 0.319004 | G_Loss: 0.669547\n",
      "  FID Score: 162.7055\n",
      "\n",
      "Epoch 111 | Time: 0.95s\n",
      "  D_Loss: 0.318506 | G_Loss: 0.667028\n",
      "\n",
      "Epoch 112 | Time: 14.80s\n",
      "  D_Loss: 0.314927 | G_Loss: 0.664465\n",
      "  FID Score: 188.0738\n",
      "\n",
      "Epoch 113 | Time: 0.95s\n",
      "  D_Loss: 0.314873 | G_Loss: 0.670866\n",
      "\n",
      "Epoch 114 | Time: 12.03s\n",
      "  D_Loss: 0.315366 | G_Loss: 0.663140\n",
      "  FID Score: 197.0921\n",
      "\n",
      "Epoch 115 | Time: 0.94s\n",
      "  D_Loss: 0.311424 | G_Loss: 0.672407\n",
      "\n",
      "Epoch 116 | Time: 14.78s\n",
      "  D_Loss: 0.308571 | G_Loss: 0.670366\n",
      "  FID Score: 152.4624\n",
      "\n",
      "Epoch 117 | Time: 0.95s\n",
      "  D_Loss: 0.306536 | G_Loss: 0.666271\n",
      "\n",
      "Epoch 118 | Time: 15.17s\n",
      "  D_Loss: 0.313038 | G_Loss: 0.669611\n",
      "  FID Score: 151.2078\n",
      "\n",
      "Epoch 119 | Time: 1.01s\n",
      "  D_Loss: 0.310380 | G_Loss: 0.670594\n",
      "\n",
      "Epoch 120 | Time: 15.59s\n",
      "  D_Loss: 0.312636 | G_Loss: 0.668274\n",
      "  FID Score: 145.1875\n",
      "\n",
      "Epoch 121 | Time: 0.97s\n",
      "  D_Loss: 0.308047 | G_Loss: 0.665525\n",
      "\n",
      "Epoch 122 | Time: 15.25s\n",
      "  D_Loss: 0.304502 | G_Loss: 0.665512\n",
      "  FID Score: 156.8350\n",
      "\n",
      "Epoch 123 | Time: 0.98s\n",
      "  D_Loss: 0.308297 | G_Loss: 0.671880\n",
      "\n",
      "Epoch 124 | Time: 14.55s\n",
      "  D_Loss: 0.308396 | G_Loss: 0.666112\n",
      "  FID Score: 157.9798\n",
      "\n",
      "Epoch 125 | Time: 0.88s\n",
      "  D_Loss: 0.301087 | G_Loss: 0.667744\n",
      "\n",
      "Epoch 126 | Time: 13.15s\n",
      "  D_Loss: 0.302303 | G_Loss: 0.666981\n",
      "  FID Score: 133.3459\n",
      "\n",
      "Epoch 127 | Time: 0.87s\n",
      "  D_Loss: 0.302571 | G_Loss: 0.665368\n",
      "\n",
      "Epoch 128 | Time: 13.83s\n",
      "  D_Loss: 0.303245 | G_Loss: 0.667216\n",
      "  FID Score: 157.8707\n",
      "\n",
      "Epoch 129 | Time: 0.88s\n",
      "  D_Loss: 0.309080 | G_Loss: 0.669213\n",
      "\n",
      "Epoch 130 | Time: 13.66s\n",
      "  D_Loss: 0.302959 | G_Loss: 0.670645\n",
      "  FID Score: 160.1464\n",
      "\n",
      "\n",
      "================================================================================\n",
      "DCGAN TRAINING COMPLETE\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dcgan_gen, dcgan_disc = train_dcgan(\n",
    "    dcgan_gen,\n",
    "    dcgan_disc,\n",
    "    minority_loader,\n",
    "    starting_epoch=91,\n",
    "    num_epochs=40,\n",
    "    latent_dim=latent_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ef09b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING DCGAN TRAINING - 40 EPOCHS\n",
      "================================================================================\n",
      "\n",
      "Epoch 131 | Time: 0.91s\n",
      "  D_Loss: 0.301055 | G_Loss: 0.667480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_16108\\3088281783.py:32: DeprecationWarning: The `disp` argument is deprecated and will be removed in SciPy 1.18.0.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n",
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_16108\\3088281783.py:32: LinAlgWarning: Matrix is singular. The result might be inaccurate or the array might not have a square root.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 | Time: 11.28s\n",
      "  D_Loss: 0.300216 | G_Loss: 0.667764\n",
      "  FID Score: 138.1669\n",
      "\n",
      "Epoch 133 | Time: 1.03s\n",
      "  D_Loss: 0.301454 | G_Loss: 0.666016\n",
      "\n",
      "Epoch 134 | Time: 14.27s\n",
      "  D_Loss: 0.300604 | G_Loss: 0.671652\n",
      "  FID Score: 154.1957\n",
      "\n",
      "Epoch 135 | Time: 0.91s\n",
      "  D_Loss: 0.297838 | G_Loss: 0.665889\n",
      "\n",
      "Epoch 136 | Time: 15.81s\n",
      "  D_Loss: 0.298130 | G_Loss: 0.671982\n",
      "  FID Score: 138.1341\n",
      "\n",
      "Epoch 137 | Time: 1.05s\n",
      "  D_Loss: 0.303703 | G_Loss: 0.668358\n",
      "\n",
      "Epoch 138 | Time: 15.31s\n",
      "  D_Loss: 0.299851 | G_Loss: 0.672150\n",
      "  FID Score: 151.7499\n",
      "\n",
      "Epoch 139 | Time: 0.90s\n",
      "  D_Loss: 0.301413 | G_Loss: 0.667649\n",
      "\n",
      "Epoch 140 | Time: 14.02s\n",
      "  D_Loss: 0.291866 | G_Loss: 0.669754\n",
      "  FID Score: 151.3447\n",
      "\n",
      "Epoch 141 | Time: 0.91s\n",
      "  D_Loss: 0.296742 | G_Loss: 0.668489\n",
      "\n",
      "Epoch 142 | Time: 14.39s\n",
      "  D_Loss: 0.295960 | G_Loss: 0.672417\n",
      "  FID Score: 127.6377\n",
      "\n",
      "Epoch 143 | Time: 0.92s\n",
      "  D_Loss: 0.296623 | G_Loss: 0.667422\n",
      "\n",
      "Epoch 144 | Time: 13.54s\n",
      "  D_Loss: 0.297901 | G_Loss: 0.673009\n",
      "  FID Score: 143.2086\n",
      "\n",
      "Epoch 145 | Time: 0.98s\n",
      "  D_Loss: 0.291811 | G_Loss: 0.671718\n",
      "\n",
      "Epoch 146 | Time: 11.64s\n",
      "  D_Loss: 0.297186 | G_Loss: 0.675886\n",
      "  FID Score: 146.6932\n",
      "\n",
      "Epoch 147 | Time: 0.96s\n",
      "  D_Loss: 0.292417 | G_Loss: 0.669210\n",
      "\n",
      "Epoch 148 | Time: 13.77s\n",
      "  D_Loss: 0.295026 | G_Loss: 0.671135\n",
      "  FID Score: 136.9957\n",
      "\n",
      "Epoch 149 | Time: 0.98s\n",
      "  D_Loss: 0.290591 | G_Loss: 0.669959\n",
      "\n",
      "Epoch 150 | Time: 14.10s\n",
      "  D_Loss: 0.290703 | G_Loss: 0.671962\n",
      "  FID Score: 117.2794\n",
      "\n",
      "Epoch 151 | Time: 1.00s\n",
      "  D_Loss: 0.293728 | G_Loss: 0.671282\n",
      "\n",
      "Epoch 152 | Time: 14.34s\n",
      "  D_Loss: 0.291404 | G_Loss: 0.674732\n",
      "  FID Score: 149.8146\n",
      "\n",
      "Epoch 153 | Time: 0.94s\n",
      "  D_Loss: 0.289126 | G_Loss: 0.670838\n",
      "\n",
      "Epoch 154 | Time: 13.97s\n",
      "  D_Loss: 0.286721 | G_Loss: 0.665706\n",
      "  FID Score: 159.7757\n",
      "\n",
      "Epoch 155 | Time: 1.08s\n",
      "  D_Loss: 0.286008 | G_Loss: 0.673593\n",
      "\n",
      "Epoch 156 | Time: 15.67s\n",
      "  D_Loss: 0.287927 | G_Loss: 0.671286\n",
      "  FID Score: 144.1143\n",
      "\n",
      "Epoch 157 | Time: 0.96s\n",
      "  D_Loss: 0.291302 | G_Loss: 0.681603\n",
      "\n",
      "Epoch 158 | Time: 12.44s\n",
      "  D_Loss: 0.290012 | G_Loss: 0.672926\n",
      "  FID Score: 136.2206\n",
      "\n",
      "Epoch 159 | Time: 0.95s\n",
      "  D_Loss: 0.283032 | G_Loss: 0.673982\n",
      "\n",
      "Epoch 160 | Time: 14.97s\n",
      "  D_Loss: 0.287336 | G_Loss: 0.665815\n",
      "  FID Score: 117.2117\n",
      "\n",
      "Epoch 161 | Time: 0.98s\n",
      "  D_Loss: 0.286037 | G_Loss: 0.673497\n",
      "\n",
      "Epoch 162 | Time: 15.18s\n",
      "  D_Loss: 0.285255 | G_Loss: 0.674911\n",
      "  FID Score: 128.2814\n",
      "\n",
      "Epoch 163 | Time: 1.08s\n",
      "  D_Loss: 0.281969 | G_Loss: 0.673932\n",
      "\n",
      "Epoch 164 | Time: 14.37s\n",
      "  D_Loss: 0.282089 | G_Loss: 0.670683\n",
      "  FID Score: 130.5646\n",
      "\n",
      "Epoch 165 | Time: 1.04s\n",
      "  D_Loss: 0.281798 | G_Loss: 0.671378\n",
      "\n",
      "Epoch 166 | Time: 10.46s\n",
      "  D_Loss: 0.282185 | G_Loss: 0.672952\n",
      "  FID Score: 115.7619\n",
      "\n",
      "Epoch 167 | Time: 0.91s\n",
      "  D_Loss: 0.284349 | G_Loss: 0.672500\n",
      "\n",
      "Epoch 168 | Time: 15.90s\n",
      "  D_Loss: 0.279668 | G_Loss: 0.674495\n",
      "  FID Score: 138.6132\n",
      "\n",
      "Epoch 169 | Time: 1.03s\n",
      "  D_Loss: 0.281795 | G_Loss: 0.675432\n",
      "\n",
      "Epoch 170 | Time: 15.50s\n",
      "  D_Loss: 0.281733 | G_Loss: 0.671076\n",
      "  FID Score: 138.8899\n",
      "\n",
      "\n",
      "================================================================================\n",
      "DCGAN TRAINING COMPLETE\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dcgan_gen, dcgan_disc = train_dcgan(\n",
    "    dcgan_gen,\n",
    "    dcgan_disc,\n",
    "    minority_loader,\n",
    "    starting_epoch=131,\n",
    "    num_epochs=40,\n",
    "    latent_dim=latent_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41205e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING DCGAN TRAINING - 40 EPOCHS\n",
      "================================================================================\n",
      "\n",
      "Epoch 171 | Time: 0.87s\n",
      "  D_Loss: 0.278413 | G_Loss: 0.674006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_16108\\3088281783.py:32: DeprecationWarning: The `disp` argument is deprecated and will be removed in SciPy 1.18.0.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n",
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_16108\\3088281783.py:32: LinAlgWarning: Matrix is singular. The result might be inaccurate or the array might not have a square root.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172 | Time: 11.21s\n",
      "  D_Loss: 0.281117 | G_Loss: 0.670733\n",
      "  FID Score: 114.7207\n",
      "\n",
      "Epoch 173 | Time: 1.03s\n",
      "  D_Loss: 0.280320 | G_Loss: 0.670960\n",
      "\n",
      "Epoch 174 | Time: 12.56s\n",
      "  D_Loss: 0.278804 | G_Loss: 0.671277\n",
      "  FID Score: 118.4346\n",
      "\n",
      "Epoch 175 | Time: 1.09s\n",
      "  D_Loss: 0.281510 | G_Loss: 0.673314\n",
      "\n",
      "Epoch 176 | Time: 11.36s\n",
      "  D_Loss: 0.279320 | G_Loss: 0.674648\n",
      "  FID Score: 129.0693\n",
      "\n",
      "Epoch 177 | Time: 0.89s\n",
      "  D_Loss: 0.279626 | G_Loss: 0.677095\n",
      "\n",
      "Epoch 178 | Time: 15.00s\n",
      "  D_Loss: 0.279706 | G_Loss: 0.676262\n",
      "  FID Score: 134.4134\n",
      "\n",
      "Epoch 179 | Time: 0.95s\n",
      "  D_Loss: 0.277238 | G_Loss: 0.678139\n",
      "\n",
      "Epoch 180 | Time: 14.96s\n",
      "  D_Loss: 0.277637 | G_Loss: 0.671616\n",
      "  FID Score: 114.5718\n",
      "\n",
      "Epoch 181 | Time: 1.02s\n",
      "  D_Loss: 0.274847 | G_Loss: 0.677895\n",
      "\n",
      "Epoch 182 | Time: 11.75s\n",
      "  D_Loss: 0.275118 | G_Loss: 0.678672\n",
      "  FID Score: 120.3658\n",
      "\n",
      "Epoch 183 | Time: 0.91s\n",
      "  D_Loss: 0.275249 | G_Loss: 0.672648\n",
      "\n",
      "Epoch 184 | Time: 14.61s\n",
      "  D_Loss: 0.276342 | G_Loss: 0.676224\n",
      "  FID Score: 130.1348\n",
      "\n",
      "Epoch 185 | Time: 0.89s\n",
      "  D_Loss: 0.275691 | G_Loss: 0.679613\n",
      "\n",
      "Epoch 186 | Time: 10.37s\n",
      "  D_Loss: 0.276597 | G_Loss: 0.672670\n",
      "  FID Score: 114.0813\n",
      "\n",
      "Epoch 187 | Time: 0.93s\n",
      "  D_Loss: 0.273508 | G_Loss: 0.674474\n",
      "\n",
      "Epoch 188 | Time: 14.25s\n",
      "  D_Loss: 0.277251 | G_Loss: 0.670996\n",
      "  FID Score: 122.7912\n",
      "\n",
      "Epoch 189 | Time: 1.02s\n",
      "  D_Loss: 0.274957 | G_Loss: 0.679020\n",
      "\n",
      "Epoch 190 | Time: 11.18s\n",
      "  D_Loss: 0.276129 | G_Loss: 0.673976\n",
      "  FID Score: 128.4075\n",
      "\n",
      "Epoch 191 | Time: 0.91s\n",
      "  D_Loss: 0.271742 | G_Loss: 0.676889\n",
      "\n",
      "Epoch 192 | Time: 14.19s\n",
      "  D_Loss: 0.277269 | G_Loss: 0.670616\n",
      "  FID Score: 114.2367\n",
      "\n",
      "Epoch 193 | Time: 0.88s\n",
      "  D_Loss: 0.278438 | G_Loss: 0.681461\n",
      "\n",
      "Epoch 194 | Time: 14.17s\n",
      "  D_Loss: 0.277273 | G_Loss: 0.677929\n",
      "  FID Score: 125.3242\n",
      "\n",
      "Epoch 195 | Time: 0.92s\n",
      "  D_Loss: 0.278703 | G_Loss: 0.674974\n",
      "\n",
      "Epoch 196 | Time: 14.02s\n",
      "  D_Loss: 0.274727 | G_Loss: 0.675146\n",
      "  FID Score: 111.3848\n",
      "\n",
      "Epoch 197 | Time: 0.91s\n",
      "  D_Loss: 0.276496 | G_Loss: 0.677400\n",
      "\n",
      "Epoch 198 | Time: 11.44s\n",
      "  D_Loss: 0.276281 | G_Loss: 0.678396\n",
      "  FID Score: 103.8936\n",
      "\n",
      "Epoch 199 | Time: 1.15s\n",
      "  D_Loss: 0.276128 | G_Loss: 0.682172\n",
      "\n",
      "Epoch 200 | Time: 12.21s\n",
      "  D_Loss: 0.274713 | G_Loss: 0.678109\n",
      "  FID Score: 107.2809\n",
      "\n",
      "Epoch 201 | Time: 0.95s\n",
      "  D_Loss: 0.276384 | G_Loss: 0.671128\n",
      "\n",
      "Epoch 202 | Time: 15.19s\n",
      "  D_Loss: 0.275496 | G_Loss: 0.681099\n",
      "  FID Score: 99.0147\n",
      "\n",
      "Epoch 203 | Time: 1.00s\n",
      "  D_Loss: 0.273276 | G_Loss: 0.671331\n",
      "\n",
      "Epoch 204 | Time: 14.98s\n",
      "  D_Loss: 0.271061 | G_Loss: 0.677692\n",
      "  FID Score: 90.4849\n",
      "\n",
      "Epoch 205 | Time: 0.88s\n",
      "  D_Loss: 0.275157 | G_Loss: 0.669850\n",
      "\n",
      "Epoch 206 | Time: 13.98s\n",
      "  D_Loss: 0.272715 | G_Loss: 0.680423\n",
      "  FID Score: 106.7702\n",
      "\n",
      "Epoch 207 | Time: 0.89s\n",
      "  D_Loss: 0.277963 | G_Loss: 0.672823\n",
      "\n",
      "Epoch 208 | Time: 11.16s\n",
      "  D_Loss: 0.272970 | G_Loss: 0.681771\n",
      "  FID Score: 102.6146\n",
      "\n",
      "Epoch 209 | Time: 0.91s\n",
      "  D_Loss: 0.273689 | G_Loss: 0.672918\n",
      "\n",
      "Epoch 210 | Time: 14.03s\n",
      "  D_Loss: 0.271083 | G_Loss: 0.675945\n",
      "  FID Score: 112.1946\n",
      "\n",
      "\n",
      "================================================================================\n",
      "DCGAN TRAINING COMPLETE\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dcgan_gen, dcgan_disc = train_dcgan(\n",
    "    dcgan_gen,\n",
    "    dcgan_disc,\n",
    "    minority_loader,\n",
    "    starting_epoch=171,\n",
    "    num_epochs=40,\n",
    "    latent_dim=latent_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6df125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING DCGAN TRAINING - 30 EPOCHS\n",
      "================================================================================\n",
      "\n",
      "Epoch 211 | Time: 0.97s\n",
      "  D_Loss: 0.273095 | G_Loss: 0.673367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_16108\\3088281783.py:32: DeprecationWarning: The `disp` argument is deprecated and will be removed in SciPy 1.18.0.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n",
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_16108\\3088281783.py:32: LinAlgWarning: Matrix is singular. The result might be inaccurate or the array might not have a square root.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212 | Time: 10.99s\n",
      "  D_Loss: 0.268685 | G_Loss: 0.677662\n",
      "  FID Score: 103.2224\n",
      "\n",
      "Epoch 213 | Time: 0.90s\n",
      "  D_Loss: 0.268398 | G_Loss: 0.672598\n",
      "\n",
      "Epoch 214 | Time: 13.66s\n",
      "  D_Loss: 0.270828 | G_Loss: 0.671816\n",
      "  FID Score: 108.7755\n",
      "\n",
      "Epoch 215 | Time: 0.91s\n",
      "  D_Loss: 0.271301 | G_Loss: 0.680873\n",
      "\n",
      "Epoch 216 | Time: 13.35s\n",
      "  D_Loss: 0.269378 | G_Loss: 0.679156\n",
      "  FID Score: 119.3399\n",
      "\n",
      "Epoch 217 | Time: 1.05s\n",
      "  D_Loss: 0.270222 | G_Loss: 0.672598\n",
      "\n",
      "Epoch 218 | Time: 11.11s\n",
      "  D_Loss: 0.268689 | G_Loss: 0.679771\n",
      "  FID Score: 96.1246\n",
      "\n",
      "Epoch 219 | Time: 0.91s\n",
      "  D_Loss: 0.272238 | G_Loss: 0.675410\n",
      "\n",
      "Epoch 220 | Time: 12.62s\n",
      "  D_Loss: 0.266781 | G_Loss: 0.680804\n",
      "  FID Score: 108.2871\n",
      "\n",
      "Epoch 221 | Time: 0.92s\n",
      "  D_Loss: 0.268754 | G_Loss: 0.673535\n",
      "\n",
      "Epoch 222 | Time: 13.92s\n",
      "  D_Loss: 0.270613 | G_Loss: 0.676236\n",
      "  FID Score: 99.6651\n",
      "\n",
      "Epoch 223 | Time: 0.91s\n",
      "  D_Loss: 0.270044 | G_Loss: 0.681073\n",
      "\n",
      "Epoch 224 | Time: 11.04s\n",
      "  D_Loss: 0.267199 | G_Loss: 0.675593\n",
      "  FID Score: 95.8992\n",
      "\n",
      "Epoch 225 | Time: 0.93s\n",
      "  D_Loss: 0.264651 | G_Loss: 0.678318\n",
      "\n",
      "Epoch 226 | Time: 15.08s\n",
      "  D_Loss: 0.269107 | G_Loss: 0.674555\n",
      "  FID Score: 104.7640\n",
      "\n",
      "Epoch 227 | Time: 0.94s\n",
      "  D_Loss: 0.271133 | G_Loss: 0.680467\n",
      "\n",
      "Epoch 228 | Time: 14.63s\n",
      "  D_Loss: 0.266270 | G_Loss: 0.675025\n",
      "  FID Score: 116.1712\n",
      "\n",
      "Epoch 229 | Time: 0.92s\n",
      "  D_Loss: 0.264156 | G_Loss: 0.684211\n",
      "\n",
      "Epoch 230 | Time: 14.91s\n",
      "  D_Loss: 0.267113 | G_Loss: 0.673208\n",
      "  FID Score: 109.8958\n",
      "\n",
      "Epoch 231 | Time: 0.89s\n",
      "  D_Loss: 0.265766 | G_Loss: 0.681596\n",
      "\n",
      "Epoch 232 | Time: 13.63s\n",
      "  D_Loss: 0.262274 | G_Loss: 0.676696\n",
      "  FID Score: 96.8000\n",
      "\n",
      "Epoch 233 | Time: 0.94s\n",
      "  D_Loss: 0.266865 | G_Loss: 0.677441\n",
      "\n",
      "Epoch 234 | Time: 14.79s\n",
      "  D_Loss: 0.266473 | G_Loss: 0.678986\n",
      "  FID Score: 95.3892\n",
      "\n",
      "Epoch 235 | Time: 0.89s\n",
      "  D_Loss: 0.265151 | G_Loss: 0.676392\n",
      "\n",
      "Epoch 236 | Time: 13.99s\n",
      "  D_Loss: 0.262340 | G_Loss: 0.678966\n",
      "  FID Score: 92.7378\n",
      "\n",
      "Epoch 237 | Time: 1.00s\n",
      "  D_Loss: 0.266213 | G_Loss: 0.675347\n",
      "\n",
      "Epoch 238 | Time: 14.42s\n",
      "  D_Loss: 0.262858 | G_Loss: 0.679339\n",
      "  FID Score: 105.0541\n",
      "\n",
      "Epoch 239 | Time: 1.06s\n",
      "  D_Loss: 0.264937 | G_Loss: 0.673908\n",
      "\n",
      "Epoch 240 | Time: 14.48s\n",
      "  D_Loss: 0.263342 | G_Loss: 0.680891\n",
      "  FID Score: 107.3677\n",
      "\n",
      "\n",
      "================================================================================\n",
      "DCGAN TRAINING COMPLETE\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dcgan_gen, dcgan_disc = train_dcgan(\n",
    "    dcgan_gen,\n",
    "    dcgan_disc,\n",
    "    minority_loader,\n",
    "    starting_epoch=211,\n",
    "    num_epochs=30,\n",
    "    latent_dim=latent_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b45ca9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dcgan_gen, dcgan_disc\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e7a09",
   "metadata": {},
   "source": [
    "epoch 236 is the best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9202ff2a",
   "metadata": {},
   "source": [
    "**Training CGAN GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0eb54998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CGAN Generator parameters: 1,394,217\n",
      "CGAN Discriminator parameters: 147,681\n"
     ]
    }
   ],
   "source": [
    "# Initialize CGAN\n",
    "num_classes = 10\n",
    "cgan_gen = CGANGenerator(latent_dim=latent_dim, num_classes=num_classes, img_channels=1).to(device)\n",
    "cgan_disc = CGANDiscriminator(num_classes=num_classes, img_channels=1).to(device)\n",
    "\n",
    "print(f\"\\nCGAN Generator parameters: {sum(p.numel() for p in cgan_gen.parameters()):,}\")\n",
    "print(f\"CGAN Discriminator parameters: {sum(p.numel() for p in cgan_disc.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1c63f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = datasets.MNIST(\n",
    "    root=\"./mnist\",\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "full_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0e2e90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING CGAN TRAINING - 100 EPOCHS\n",
      "================================================================================\n",
      "\n",
      "Epoch 1 | Time: 54.86s\n",
      "  D_Loss: 1.146193 | G_Loss: 0.625094\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_16108\\3088281783.py:32: DeprecationWarning: The `disp` argument is deprecated and will be removed in SciPy 1.18.0.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n",
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_16108\\3088281783.py:32: LinAlgWarning: Matrix is singular. The result might be inaccurate or the array might not have a square root.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Time: 50.10s\n",
      "  D_Loss: 0.960949 | G_Loss: 0.667081\n",
      "  FID Score: 370.3369\n",
      "\n",
      "Epoch 3 | Time: 40.70s\n",
      "  D_Loss: 0.786557 | G_Loss: 0.648492\n",
      "\n",
      "Epoch 4 | Time: 57.38s\n",
      "  D_Loss: 0.649404 | G_Loss: 0.716543\n",
      "  FID Score: 319.0408\n",
      "\n",
      "Epoch 5 | Time: 43.28s\n",
      "  D_Loss: 0.609288 | G_Loss: 0.749667\n",
      "\n",
      "Epoch 6 | Time: 42.31s\n",
      "  D_Loss: 0.367074 | G_Loss: 0.626096\n",
      "  FID Score: 395.3452\n",
      "\n",
      "Epoch 7 | Time: 30.22s\n",
      "  D_Loss: 0.362740 | G_Loss: 0.629262\n",
      "\n",
      "Epoch 8 | Time: 41.84s\n",
      "  D_Loss: 0.345884 | G_Loss: 0.666167\n",
      "  FID Score: 303.0732\n",
      "\n",
      "Epoch 9 | Time: 29.52s\n",
      "  D_Loss: 0.332199 | G_Loss: 0.692052\n",
      "\n",
      "Epoch 10 | Time: 42.95s\n",
      "  D_Loss: 0.324145 | G_Loss: 0.706850\n",
      "  FID Score: 263.5411\n",
      "\n",
      "Epoch 11 | Time: 32.94s\n",
      "  D_Loss: 0.322066 | G_Loss: 0.711228\n",
      "\n",
      "Epoch 12 | Time: 49.77s\n",
      "  D_Loss: 0.314607 | G_Loss: 0.720868\n",
      "  FID Score: 294.5211\n",
      "\n",
      "Epoch 13 | Time: 31.28s\n",
      "  D_Loss: 0.303359 | G_Loss: 0.753724\n",
      "\n",
      "Epoch 14 | Time: 47.99s\n",
      "  D_Loss: 0.300660 | G_Loss: 0.756405\n",
      "  FID Score: 257.6621\n",
      "\n",
      "Epoch 15 | Time: 31.65s\n",
      "  D_Loss: 0.293226 | G_Loss: 0.765654\n",
      "\n",
      "Epoch 16 | Time: 43.31s\n",
      "  D_Loss: 0.289579 | G_Loss: 0.774015\n",
      "  FID Score: 276.9357\n",
      "\n",
      "Epoch 17 | Time: 33.34s\n",
      "  D_Loss: 0.279777 | G_Loss: 0.790538\n",
      "\n",
      "Epoch 18 | Time: 45.98s\n",
      "  D_Loss: 0.276207 | G_Loss: 0.810663\n",
      "  FID Score: 318.1525\n",
      "\n",
      "Epoch 19 | Time: 30.31s\n",
      "  D_Loss: 0.278769 | G_Loss: 0.804215\n",
      "\n",
      "Epoch 20 | Time: 47.29s\n",
      "  D_Loss: 0.269928 | G_Loss: 0.822509\n",
      "  FID Score: 329.9480\n",
      "\n",
      "Epoch 21 | Time: 31.15s\n",
      "  D_Loss: 0.259963 | G_Loss: 0.867115\n",
      "\n",
      "Epoch 22 | Time: 37.96s\n",
      "  D_Loss: 0.261653 | G_Loss: 0.857263\n",
      "  FID Score: 304.5717\n",
      "\n",
      "Epoch 23 | Time: 29.29s\n",
      "  D_Loss: 0.259581 | G_Loss: 0.875106\n",
      "\n",
      "Epoch 24 | Time: 37.48s\n",
      "  D_Loss: 0.250850 | G_Loss: 0.902407\n",
      "  FID Score: 363.1792\n",
      "\n",
      "Epoch 25 | Time: 29.35s\n",
      "  D_Loss: 0.251197 | G_Loss: 0.898744\n",
      "\n",
      "Epoch 26 | Time: 38.90s\n",
      "  D_Loss: 0.248495 | G_Loss: 0.907908\n",
      "  FID Score: 361.0573\n",
      "\n",
      "Epoch 27 | Time: 31.07s\n",
      "  D_Loss: 0.239584 | G_Loss: 0.939732\n",
      "\n",
      "Epoch 28 | Time: 37.96s\n",
      "  D_Loss: 0.248827 | G_Loss: 0.926212\n",
      "  FID Score: 316.9648\n",
      "\n",
      "Epoch 29 | Time: 27.82s\n",
      "  D_Loss: 0.254316 | G_Loss: 0.903929\n",
      "\n",
      "Epoch 30 | Time: 38.60s\n",
      "  D_Loss: 0.235685 | G_Loss: 0.965974\n",
      "  FID Score: 357.8622\n",
      "\n",
      "Epoch 31 | Time: 28.63s\n",
      "  D_Loss: 0.238483 | G_Loss: 0.957061\n",
      "\n",
      "Epoch 32 | Time: 38.58s\n",
      "  D_Loss: 0.241680 | G_Loss: 0.942412\n",
      "  FID Score: 311.7498\n",
      "\n",
      "Epoch 33 | Time: 28.50s\n",
      "  D_Loss: 0.237635 | G_Loss: 0.953804\n",
      "\n",
      "Epoch 34 | Time: 41.46s\n",
      "  D_Loss: 0.238611 | G_Loss: 0.962521\n",
      "  FID Score: 316.1102\n",
      "\n",
      "Epoch 35 | Time: 28.87s\n",
      "  D_Loss: 0.240282 | G_Loss: 0.951128\n",
      "\n",
      "Epoch 36 | Time: 37.88s\n",
      "  D_Loss: 0.233808 | G_Loss: 0.974590\n",
      "  FID Score: 306.5811\n",
      "\n",
      "Epoch 37 | Time: 28.97s\n",
      "  D_Loss: 0.234099 | G_Loss: 0.982987\n",
      "\n",
      "Epoch 38 | Time: 42.16s\n",
      "  D_Loss: 0.233992 | G_Loss: 0.973770\n",
      "  FID Score: 425.2208\n",
      "\n",
      "Epoch 39 | Time: 29.28s\n",
      "  D_Loss: 0.226807 | G_Loss: 1.003369\n",
      "\n",
      "Epoch 40 | Time: 36.60s\n",
      "  D_Loss: 0.236126 | G_Loss: 0.969859\n",
      "  FID Score: 237.2289\n",
      "\n",
      "Epoch 41 | Time: 27.17s\n",
      "  D_Loss: 0.223329 | G_Loss: 1.018136\n",
      "\n",
      "Epoch 42 | Time: 35.87s\n",
      "  D_Loss: 0.239007 | G_Loss: 0.984021\n",
      "  FID Score: 206.9000\n",
      "\n",
      "Epoch 43 | Time: 27.17s\n",
      "  D_Loss: 0.228166 | G_Loss: 0.997982\n",
      "\n",
      "Epoch 44 | Time: 39.87s\n",
      "  D_Loss: 0.233831 | G_Loss: 0.995819\n",
      "  FID Score: 238.9217\n",
      "\n",
      "Epoch 45 | Time: 27.22s\n",
      "  D_Loss: 0.227859 | G_Loss: 1.016571\n",
      "\n",
      "Epoch 46 | Time: 39.28s\n",
      "  D_Loss: 0.220889 | G_Loss: 1.043991\n",
      "  FID Score: 285.1766\n",
      "\n",
      "Epoch 47 | Time: 27.09s\n",
      "  D_Loss: 0.233135 | G_Loss: 1.002196\n",
      "\n",
      "Epoch 48 | Time: 37.20s\n",
      "  D_Loss: 0.227982 | G_Loss: 1.015512\n",
      "  FID Score: 226.4633\n",
      "\n",
      "Epoch 49 | Time: 27.32s\n",
      "  D_Loss: 0.221382 | G_Loss: 1.037935\n",
      "\n",
      "Epoch 50 | Time: 36.28s\n",
      "  D_Loss: 0.231765 | G_Loss: 0.998507\n",
      "  FID Score: 226.5595\n",
      "\n",
      "Epoch 51 | Time: 27.22s\n",
      "  D_Loss: 0.224436 | G_Loss: 1.040536\n",
      "\n",
      "Epoch 52 | Time: 36.05s\n",
      "  D_Loss: 0.208566 | G_Loss: 1.097858\n",
      "  FID Score: 282.6751\n",
      "\n",
      "Epoch 53 | Time: 27.45s\n",
      "  D_Loss: 0.212355 | G_Loss: 1.098620\n",
      "\n",
      "Epoch 54 | Time: 38.12s\n",
      "  D_Loss: 0.227422 | G_Loss: 1.033150\n",
      "  FID Score: 280.7276\n",
      "\n",
      "Epoch 55 | Time: 27.17s\n",
      "  D_Loss: 0.220825 | G_Loss: 1.052860\n",
      "\n",
      "Epoch 56 | Time: 36.25s\n",
      "  D_Loss: 0.229054 | G_Loss: 1.018851\n",
      "  FID Score: 263.7541\n",
      "\n",
      "Epoch 57 | Time: 27.24s\n",
      "  D_Loss: 0.213306 | G_Loss: 1.082619\n",
      "\n",
      "Epoch 58 | Time: 36.50s\n",
      "  D_Loss: 0.232945 | G_Loss: 1.036354\n",
      "  FID Score: 265.9434\n",
      "\n",
      "Epoch 59 | Time: 27.42s\n",
      "  D_Loss: 0.220219 | G_Loss: 1.052195\n",
      "\n",
      "Epoch 60 | Time: 36.23s\n",
      "  D_Loss: 0.219897 | G_Loss: 1.057659\n",
      "  FID Score: 321.4898\n",
      "\n",
      "Epoch 61 | Time: 27.28s\n",
      "  D_Loss: 0.216665 | G_Loss: 1.093773\n",
      "\n",
      "Epoch 62 | Time: 36.41s\n",
      "  D_Loss: 0.209088 | G_Loss: 1.101353\n",
      "  FID Score: 270.0839\n",
      "\n",
      "Epoch 63 | Time: 27.11s\n",
      "  D_Loss: 0.217172 | G_Loss: 1.089264\n",
      "\n",
      "Epoch 64 | Time: 36.26s\n",
      "  D_Loss: 0.210551 | G_Loss: 1.094349\n",
      "  FID Score: 350.1097\n",
      "\n",
      "Epoch 65 | Time: 27.74s\n",
      "  D_Loss: 0.211985 | G_Loss: 1.097773\n",
      "\n",
      "Epoch 66 | Time: 36.22s\n",
      "  D_Loss: 0.221630 | G_Loss: 1.069637\n",
      "  FID Score: 216.3358\n",
      "\n",
      "Epoch 67 | Time: 27.10s\n",
      "  D_Loss: 0.215403 | G_Loss: 1.095410\n",
      "\n",
      "Epoch 68 | Time: 36.33s\n",
      "  D_Loss: 0.219179 | G_Loss: 1.069093\n",
      "  FID Score: 274.5243\n",
      "\n",
      "Epoch 69 | Time: 27.19s\n",
      "  D_Loss: 0.209317 | G_Loss: 1.117360\n",
      "\n",
      "Epoch 70 | Time: 36.08s\n",
      "  D_Loss: 0.211705 | G_Loss: 1.114355\n",
      "  FID Score: 258.6511\n",
      "\n",
      "Epoch 71 | Time: 27.25s\n",
      "  D_Loss: 0.212569 | G_Loss: 1.100244\n",
      "\n",
      "Epoch 72 | Time: 36.62s\n",
      "  D_Loss: 0.218863 | G_Loss: 1.072945\n",
      "  FID Score: 279.1179\n",
      "\n",
      "Epoch 73 | Time: 27.02s\n",
      "  D_Loss: 0.204819 | G_Loss: 1.113305\n",
      "\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Internal error in scipy.linalg.sqrtm: -101",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLinAlgError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m cgan_gen, cgan_disc = \u001b[43mtrain_cgan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcgan_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcgan_disc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfull_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mminority_class_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 78\u001b[39m, in \u001b[36mtrain_cgan\u001b[39m\u001b[34m(generator, discriminator, dataloader, minority_class_idx, num_epochs, starting_epoch, latent_dim, save_path, model_path)\u001b[39m\n\u001b[32m     76\u001b[39m         sample_labels = torch.full((\u001b[32m128\u001b[39m,), minority_class_idx, dtype=torch.long).to(device)\n\u001b[32m     77\u001b[39m         fake_batch = generator(z, sample_labels)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         fid_score = \u001b[43mcalculate_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m epoch_time = time.time() - epoch_start\n\u001b[32m     82\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mcalculate_fid\u001b[39m\u001b[34m(real_images, fake_images, device)\u001b[39m\n\u001b[32m     29\u001b[39m mu_fake, sigma_fake = act_fake.mean(axis=\u001b[32m0\u001b[39m), np.cov(act_fake, rowvar=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     31\u001b[39m diff = mu_real - mu_fake\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m covmean, _ = \u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrtm\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigma_real\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigma_fake\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.iscomplexobj(covmean):\n\u001b[32m     35\u001b[39m     covmean = covmean.real\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\linalg\\_matfuncs.py:534\u001b[39m, in \u001b[36msqrtm\u001b[39m\u001b[34m(A, disp, blocksize)\u001b[39m\n\u001b[32m    532\u001b[39m res, isIllconditioned, isSingular, info = recursive_schur_sqrtm(a)\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info < \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInternal error in scipy.linalg.sqrtm: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    536\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isSingular \u001b[38;5;129;01mor\u001b[39;00m isIllconditioned:\n\u001b[32m    537\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m isSingular:\n",
      "\u001b[31mLinAlgError\u001b[39m: Internal error in scipy.linalg.sqrtm: -101"
     ]
    }
   ],
   "source": [
    "cgan_gen, cgan_disc = train_cgan(\n",
    "    cgan_gen,\n",
    "    cgan_disc,\n",
    "    full_loader,\n",
    "    minority_class_idx,\n",
    "    num_epochs=100,\n",
    "    latent_dim=latent_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c48ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del cgan_gen, cgan_disc\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ebfa3",
   "metadata": {},
   "source": [
    "best epoch is 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9e4190c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directories for synthetic images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "\n",
    "# Create directories for synthetic images\n",
    "os.makedirs('synthetic_data/vanilla_gan', exist_ok=True)\n",
    "os.makedirs('synthetic_data/dcgan', exist_ok=True)\n",
    "os.makedirs('synthetic_data/cgan', exist_ok=True)\n",
    "\n",
    "print(\"Created directories for synthetic images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8f640c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded Vanilla GAN from epoch 72\n",
      "‚úì Loaded DCGAN from epoch 236\n",
      "‚úì Loaded CGAN from epoch 40\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "\n",
    "# Load Vanilla GAN\n",
    "vanilla_gen = VanillaGenerator(latent_dim=latent_dim, img_size=28).to(device)\n",
    "checkpoint_vanilla = torch.load('gan_saved_models/vanilla_gan/model_epoch_72.pt')\n",
    "vanilla_gen.load_state_dict(checkpoint_vanilla['generator_state_dict'])\n",
    "vanilla_gen.eval()\n",
    "print(\"‚úì Loaded Vanilla GAN from epoch 72\")\n",
    "\n",
    "# Load DCGAN \n",
    "dcgan_gen = DCGANGenerator(latent_dim=latent_dim, img_channels=1).to(device)\n",
    "checkpoint_dcgan = torch.load('gan_saved_models/dcgan/model_epoch_236.pt')\n",
    "dcgan_gen.load_state_dict(checkpoint_dcgan['generator_state_dict'])\n",
    "dcgan_gen.eval()\n",
    "print(\"‚úì Loaded DCGAN from epoch 236\")\n",
    "\n",
    "# Load CGAN \n",
    "num_classes = 10    \n",
    "cgan_gen = CGANGenerator(latent_dim=latent_dim, num_classes=num_classes, img_channels=1).to(device)\n",
    "checkpoint_cgan = torch.load('gan_saved_models/cgan/model_epoch_40.pt')\n",
    "cgan_gen.load_state_dict(checkpoint_cgan['generator_state_dict'])\n",
    "cgan_gen.eval()\n",
    "print(\"‚úì Loaded CGAN from epoch 40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b22b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_images(generator, num_images, save_dir, gan_type='vanilla', minority_class_idx=None):\n",
    "    \"\"\"\n",
    "    Generate synthetic images and save them individually\n",
    "    \n",
    "    Args:\n",
    "        generator: trained generator model\n",
    "        num_images: number of images to generate\n",
    "        save_dir: directory to save images\n",
    "        gan_type: 'vanilla', 'dcgan', or 'cgan'\n",
    "        minority_class_idx: class index for CGAN\n",
    "    \"\"\"\n",
    "    generator.eval()\n",
    "    batch_size = 64  # Generate in batches to avoid memory issues\n",
    "    num_batches = (num_images + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Generating {num_images} images for {gan_type.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    img_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx in range(num_batches):\n",
    "            # Calculate batch size for last batch\n",
    "            current_batch_size = min(batch_size, num_images - img_count)\n",
    "            \n",
    "            # Generate noise\n",
    "            z = torch.randn(current_batch_size, latent_dim).to(device)\n",
    "            \n",
    "            # Generate images\n",
    "            if gan_type == 'cgan':\n",
    "                labels = torch.full((current_batch_size,), minority_class_idx, dtype=torch.long).to(device)\n",
    "                fake_imgs = generator(z, labels)\n",
    "            else:\n",
    "                fake_imgs = generator(z)\n",
    "            \n",
    "            # Save each image individually\n",
    "            for i in range(current_batch_size):\n",
    "                img = fake_imgs[i]\n",
    "                # Denormalize from [-1, 1] to [0, 1]\n",
    "                img = (img + 1) / 2\n",
    "                img = torch.clamp(img, 0, 1)\n",
    "                \n",
    "                # Save image\n",
    "                img_path = os.path.join(save_dir, f'synthetic_{img_count + 4800 :05d}.png')\n",
    "                save_image(img, img_path)\n",
    "                img_count += 1\n",
    "            \n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"Generated {img_count}/{num_images} images...\")\n",
    "    \n",
    "    print(f\"‚úì Complete! Generated {img_count} images in {save_dir}\")\n",
    "    return img_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbd9ae75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Generating 900 images for VANILLA\n",
      "============================================================\n",
      "Generated 640/900 images...\n",
      "‚úì Complete! Generated 900 images in synthetic_data/vanilla_gan\n",
      "\n",
      "============================================================\n",
      "Generating 900 images for DCGAN\n",
      "============================================================\n",
      "Generated 640/900 images...\n",
      "‚úì Complete! Generated 900 images in synthetic_data/dcgan\n",
      "\n",
      "============================================================\n",
      "Generating 900 images for CGAN\n",
      "============================================================\n",
      "Generated 640/900 images...\n",
      "‚úì Complete! Generated 900 images in synthetic_data/cgan\n",
      "\n",
      "============================================================\n",
      "GENERATION SUMMARY\n",
      "============================================================\n",
      "Vanilla GAN: 900 images\n",
      "DCGAN: 900 images\n",
      "CGAN: 900 images\n",
      "Total synthetic images: 2700\n"
     ]
    }
   ],
   "source": [
    "num_synthetic = 900\n",
    "minority_class_idx = 0\n",
    "\n",
    "# Generate for Vanilla GAN\n",
    "count_vanilla = generate_synthetic_images(\n",
    "    vanilla_gen, \n",
    "    num_synthetic, \n",
    "    'synthetic_data/vanilla_gan',\n",
    "    gan_type='vanilla'\n",
    ")\n",
    "\n",
    "# Generate for DCGAN\n",
    "count_dcgan = generate_synthetic_images(\n",
    "    dcgan_gen,\n",
    "    num_synthetic,\n",
    "    'synthetic_data/dcgan',\n",
    "    gan_type='dcgan'\n",
    ")\n",
    "\n",
    "# Generate for CGAN (class 2 = Tuberculosis)\n",
    "count_cgan = generate_synthetic_images(\n",
    "    cgan_gen,\n",
    "    num_synthetic,\n",
    "    'synthetic_data/cgan',\n",
    "    gan_type='cgan',\n",
    "    minority_class_idx=minority_class_idx\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"GENERATION SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Vanilla GAN: {count_vanilla} images\")\n",
    "print(f\"DCGAN: {count_dcgan} images\")\n",
    "print(f\"CGAN: {count_cgan} images\")\n",
    "print(f\"Total synthetic images: {count_vanilla + count_dcgan + count_cgan}\")\n",
    "# the output is after adding 4800 already before"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
