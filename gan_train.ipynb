{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd7c9364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\cuda\\__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d288ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7da39de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "Normal: 9188 images\n",
      "Pneumonia: 4145 images\n",
      "Tuberculosis: 1788 images\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data/low_res'\n",
    "dataset = datasets.ImageFolder(root=data_path)\n",
    "\n",
    "# Analyze class distribution\n",
    "class_counts = Counter(dataset.targets)\n",
    "class_names = dataset.classes\n",
    "print(\"Class distribution:\")\n",
    "for idx, name in enumerate(class_names):\n",
    "    print(f\"{name}: {class_counts[idx]} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23699ab3",
   "metadata": {},
   "source": [
    "## Calculating the Normalization mean and std specifically for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "023d354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(dataset):\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "    dataset.transform = transform\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Initialize tensors to store the sum of pixel values for each (RGB) channel.\n",
    "    channel_sum = torch.zeros(3)\n",
    "    # Initialize tensors to store the sum of squared pixel values for each channel.\n",
    "    channel_sum_sq = torch.zeros(3)\n",
    "    # Initialize a counter for the total number of pixels.\n",
    "    num_pixels = 0\n",
    "\n",
    "    # Wrap the loader with tqdm to create a progress bar for monitoring.\n",
    "    for images, _ in tqdm(loader, desc=\"Calculating Dataset Stats\"):\n",
    "        # Add the total number of pixels in this batch to the running total.\n",
    "        num_pixels += images.size(0) * images.size(2) * images.size(3)\n",
    "        \n",
    "        # Sum the pixel values across the batch, height, and width dimensions,\n",
    "        # leaving only the channel dimension. Add this to the running total.\n",
    "        channel_sum += images.sum(dim=[0, 2, 3])\n",
    "        \n",
    "        # Square each pixel value, then sum them up similarly to the step above.\n",
    "        channel_sum_sq += (images ** 2).sum(dim=[0, 2, 3])\n",
    "\n",
    "    # Calculate the mean for each channel.\n",
    "    mean = channel_sum / num_pixels\n",
    "    # Calculate the standard deviation using the formula: sqrt(E[X^2] - E[X]^2)\n",
    "    std = (channel_sum_sq / num_pixels - mean ** 2) ** 0.5\n",
    "\n",
    "    # Return the calculated mean and standard deviation.\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad1922f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34348d0acd54f2d99ba647311b8a905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Dataset Stats:   0%|          | 0/237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean, std = calculate_mean_std(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b855e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([0.0556, 0.0556, 0.0556])\n",
      "std: tensor([0.4764, 0.4764, 0.4764])\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean: {mean}\")\n",
    "print(f\"std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6cd84e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.0556, 0.0556, 0.0556], [0.4764, 0.4764, 0.4764])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9fe78ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcfc865f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minority class: Tuberculosis with 1788 images\n"
     ]
    }
   ],
   "source": [
    "# Plot class distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(class_names, [class_counts[i] for i in range(len(class_names))])\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Class Distribution (Imbalanced Dataset)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('class_distribution.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Minority class: Tuberculosis with 1788 images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7aef7051",
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_class_idx = 2\n",
    "minority_class_name = \"Tuberculosis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "901d32fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minority class dataset size: 1788\n",
      "Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "# Filter minority class samples\n",
    "minority_indices = [i for i, label in enumerate(dataset.targets) if label == minority_class_idx]\n",
    "minority_dataset = torch.utils.data.Subset(dataset, minority_indices)\n",
    "\n",
    "# Create DataLoader for minority class\n",
    "batch_size = 32\n",
    "minority_loader = DataLoader(minority_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"Minority class dataset size: {len(minority_dataset)}\")\n",
    "print(f\"Batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a4316f",
   "metadata": {},
   "source": [
    "#  Defining the Models Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ec94b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class VanillaGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, img_size=128):\n",
    "        super(VanillaGenerator, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(1024, 3 * img_size * img_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 3, self.img_size, self.img_size)\n",
    "        return img\n",
    "\n",
    "# Discriminator\n",
    "class VanillaDiscriminator(nn.Module):\n",
    "    def __init__(self, img_size=128):\n",
    "        super(VanillaDiscriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(3 * img_size * img_size, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "945f084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGANGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, img_channels=3):\n",
    "        super(DCGANGenerator, self).__init__()\n",
    "        \n",
    "        self.init_size = 4  # Initial size before upsampling\n",
    "        self.l1 = nn.Linear(latent_dim, 256 * self.init_size ** 2)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.BatchNorm2d(256),\n",
    "            \n",
    "            # (256, 4, 4) -> (128, 8, 8)\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # (128, 8, 8) -> (64, 16, 16)\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # (64, 16, 16) -> (3, 32, 32)\n",
    "            nn.ConvTranspose2d(64, img_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 256, self.init_size, self.init_size)\n",
    "        img = self.model(out)\n",
    "        return img\n",
    "\n",
    "class DCGANDiscriminator(nn.Module):\n",
    "    def __init__(self, img_channels=3):\n",
    "        super(DCGANDiscriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # Input: (C, 32, 32)\n",
    "            nn.Conv2d(img_channels, 64, kernel_size=4, stride=2, padding=1),  # -> (64, 16, 16)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # -> (128, 8, 8)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),  # -> (256, 4, 4)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 1, kernel_size=4, stride=1, padding=0),  # -> (1, 1, 1)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        validity = self.model(img)\n",
    "        return validity.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fbf4b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGANGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, num_classes=3, img_channels=3):\n",
    "        super(CGANGenerator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, latent_dim)\n",
    "        \n",
    "        self.init_size = 8\n",
    "        self.l1 = nn.Linear(latent_dim * 2, 512 * self.init_size ** 2)\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Upsample(scale_factor=2), # 16x16\n",
    "\n",
    "            nn.Conv2d(512, 256, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(256, 128, 3, stride=1, padding=1), \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2), # 32x32\n",
    "\n",
    "            nn.Conv2d(64, img_channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, labels):\n",
    "        label_input = self.label_emb(labels)\n",
    "        gen_input = torch.cat([z, label_input], -1)\n",
    "        out = self.l1(gen_input)\n",
    "        out = out.view(out.shape[0], 512, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "class CGANDiscriminator(nn.Module):\n",
    "    def __init__(self, num_classes=3, img_channels=3):\n",
    "        super(CGANDiscriminator, self).__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, 32 * 32)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(img_channels + 1, 64, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(512, 1, 2, stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self, img, labels):\n",
    "        label_input = self.label_emb(labels).view(labels.shape[0], 1, 32, 32)\n",
    "        d_in = torch.cat([img, label_input], 1)\n",
    "        validity = self.model(d_in)\n",
    "        return validity.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b1122af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torchvision.utils import save_image\n",
    "from scipy import linalg\n",
    "import numpy as np\n",
    "from torchvision.models import inception_v3\n",
    "\n",
    "# FID Score Calculation\n",
    "def calculate_fid(real_images, fake_images, device):\n",
    "    \"\"\"Calculate Fr√©chet Inception Distance\"\"\"\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).to(device)\n",
    "    inception_model.fc = nn.Identity()\n",
    "    inception_model.eval()\n",
    "    \n",
    "    def get_activations(images):\n",
    "        with torch.no_grad():\n",
    "            # Resize to 299x299 for Inception\n",
    "            images_resized = nn.functional.interpolate(images, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "            pred = inception_model(images_resized)\n",
    "        return pred.cpu().numpy()\n",
    "    \n",
    "    act_real = get_activations(real_images)\n",
    "    act_fake = get_activations(fake_images)\n",
    "    \n",
    "    mu_real, sigma_real = act_real.mean(axis=0), np.cov(act_real, rowvar=False)\n",
    "    mu_fake, sigma_fake = act_fake.mean(axis=0), np.cov(act_fake, rowvar=False)\n",
    "    \n",
    "    diff = mu_real - mu_fake\n",
    "    covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n",
    "    \n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    \n",
    "    fid = diff.dot(diff) + np.trace(sigma_real + sigma_fake - 2 * covmean)\n",
    "    return fid\n",
    "\n",
    "# Save sample images\n",
    "def save_sample_images(generator, epoch, latent_dim, save_path, num_samples=25, labels=None):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_samples, latent_dim).to(device)\n",
    "        if labels is not None:\n",
    "            # For CGAN\n",
    "            sample_labels = torch.full((num_samples,), labels, dtype=torch.long).to(device)\n",
    "            gen_imgs = generator(z, sample_labels)\n",
    "        else:\n",
    "            gen_imgs = generator(z)\n",
    "        \n",
    "        save_image(gen_imgs.data, f\"{save_path}/epoch_{epoch}.png\", nrow=5, normalize=True)\n",
    "    generator.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2f55a9",
   "metadata": {},
   "source": [
    "# Defining the Training Loop for each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d6601694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vanilla_gan(generator, discriminator, dataloader, num_epochs=100, starting_epoch=1, latent_dim=100, \n",
    "                      save_path='generated_images/vanilla_gan', model_path='models/vanilla_gan'):\n",
    "    \n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    \n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # Create metrics file\n",
    "    metrics_file = f'{save_path}/training_metrics.txt'\n",
    "    with open(metrics_file, 'w') as f:\n",
    "        f.write(\"Epoch,Time(s),D_Loss,G_Loss,FID_Score\\n\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STARTING VANILLA GAN TRAINING - {num_epochs} EPOCHS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    for epoch in range(starting_epoch, num_epochs + 1):\n",
    "        epoch_start = time.time()\n",
    "        epoch_d_loss = 0\n",
    "        epoch_g_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for i, (imgs, _) in enumerate(dataloader):\n",
    "            batch_size = imgs.size(0)\n",
    "            real_imgs = imgs.to(device)\n",
    "            \n",
    "            # Labels\n",
    "            real_labels = torch.ones(batch_size, 1).to(device) * 0.9\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device) + 0.1\n",
    "            \n",
    "\n",
    "            # Train Discriminator but skip training it every 3 epochs\n",
    "            if epoch % 3 == 0:\n",
    "                pass\n",
    "            else:\n",
    "                optimizer_D.zero_grad()\n",
    "                real_discriminator_prediction = discriminator(real_imgs)\n",
    "                real_loss = criterion(real_discriminator_prediction, real_labels)\n",
    "                \n",
    "                z = torch.randn(batch_size, latent_dim).to(device)\n",
    "                fake_imgs = generator(z)\n",
    "                fake_loss = criterion(discriminator(fake_imgs.detach()), fake_labels)\n",
    "                \n",
    "                d_loss = (real_loss + fake_loss) / 2\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "            \n",
    "            # Train Generator\n",
    "            optimizer_G.zero_grad()\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            gen_imgs = generator(z)\n",
    "            g_loss = criterion(discriminator(gen_imgs), real_labels)\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        # Calculate average losses\n",
    "        avg_d_loss = epoch_d_loss / num_batches\n",
    "        avg_g_loss = epoch_g_loss / num_batches\n",
    "        \n",
    "\n",
    "        fid_score = 0.0\n",
    "        if epoch % 2 == 0:\n",
    "            with torch.no_grad():\n",
    "                real_batch = next(iter(dataloader))[0][:64].to(device)\n",
    "                z = torch.randn(64, latent_dim).to(device)\n",
    "                fake_batch = generator(z)\n",
    "                fid_score = calculate_fid(real_batch, fake_batch, device)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Epoch {epoch} | Time: {epoch_time:.2f}s\")\n",
    "        print(f\"  D_Loss: {avg_d_loss:.6f} | G_Loss: {avg_g_loss:.6f}\")\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"  FID Score: {fid_score:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        # Save metrics to file\n",
    "        with open(metrics_file, 'a') as f:\n",
    "            f.write(f\"{epoch},{epoch_time:.2f},{avg_d_loss:.6f},{avg_g_loss:.6f},{fid_score:.4f}\\n\")\n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            save_sample_images(generator, epoch, latent_dim, save_path)\n",
    "        \n",
    "        # Save model after epoch 5\n",
    "        if epoch > 20 and epoch % 4 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'generator_state_dict': generator.state_dict(),\n",
    "                'discriminator_state_dict': discriminator.state_dict(),\n",
    "                'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "                'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "            }, f\"{model_path}/model_epoch_{epoch}.pt\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"VANILLA GAN TRAINING COMPLETE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return generator, discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5843f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dcgan(generator, discriminator, dataloader, starting_epoch=1, num_epochs=100, latent_dim=100,\n",
    "                save_path='generated_images/dcgan', model_path='models/dcgan'):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    \n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    metrics_file = f'{save_path}/training_metrics.txt'\n",
    "    with open(metrics_file, 'w') as f:\n",
    "        f.write(\"Epoch,Time(s),D_Loss,G_Loss,FID_Score\\n\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STARTING DCGAN TRAINING - {num_epochs} EPOCHS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    for epoch in range(starting_epoch, num_epochs + 1):\n",
    "        epoch_start = time.time()\n",
    "        epoch_d_loss = 0\n",
    "        epoch_g_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for i, (imgs, _) in enumerate(dataloader):\n",
    "            batch_size = imgs.size(0)\n",
    "            real_imgs = imgs.to(device)\n",
    "            \n",
    "            real_labels = torch.ones(batch_size, 1).to(device) * 0.9\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device) + 0.1\n",
    "            \n",
    "            # Train Discriminator but skip training it every 3 epochs\n",
    "            if epoch % 3 == 0:\n",
    "                pass\n",
    "            else:\n",
    "                optimizer_D.zero_grad()\n",
    "                real_loss = criterion(discriminator(real_imgs), real_labels)\n",
    "                \n",
    "                z = torch.randn(batch_size, latent_dim).to(device)\n",
    "                fake_imgs = generator(z)\n",
    "                fake_loss = criterion(discriminator(fake_imgs.detach()), fake_labels)\n",
    "                \n",
    "                d_loss = (real_loss + fake_loss) / 2\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "            \n",
    "            # Train Generator\n",
    "            optimizer_G.zero_grad()\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            gen_imgs = generator(z)\n",
    "            g_loss = criterion(discriminator(gen_imgs), real_labels)\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_d_loss = epoch_d_loss / num_batches\n",
    "        avg_g_loss = epoch_g_loss / num_batches\n",
    "        \n",
    "        # Calculate FID every 2 epochs\n",
    "        fid_score = 0.0\n",
    "        if epoch % 2 == 0:\n",
    "            with torch.no_grad():\n",
    "                real_batch = next(iter(dataloader))[0][:64].to(device)\n",
    "                z = torch.randn(64, latent_dim).to(device)\n",
    "                fake_batch = generator(z)\n",
    "                fid_score = calculate_fid(real_batch, fake_batch, device)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        print(f\"Epoch {epoch} | Time: {epoch_time:.2f}s\")\n",
    "        print(f\"  D_Loss: {avg_d_loss:.6f} | G_Loss: {avg_g_loss:.6f}\")\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"  FID Score: {fid_score:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        with open(metrics_file, 'a') as f:\n",
    "            f.write(f\"{epoch},{epoch_time:.2f},{avg_d_loss:.6f},{avg_g_loss:.6f},{fid_score:.4f}\\n\")\n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            save_sample_images(generator, epoch, latent_dim, save_path)\n",
    "        \n",
    "        if epoch > 20 and epoch % 4 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'generator_state_dict': generator.state_dict(),\n",
    "                'discriminator_state_dict': discriminator.state_dict(),\n",
    "                'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "                'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "            }, f\"{model_path}/model_epoch_{epoch}.pt\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"DCGAN TRAINING COMPLETE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return generator, discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "38a0518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cgan(generator, discriminator, dataloader, minority_class_idx, num_epochs=100, starting_epoch=1, \n",
    "               latent_dim=100, save_path='generated_images/cgan', model_path='models/cgan'):\n",
    "    \n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    metrics_file = f'{save_path}/training_metrics.txt'\n",
    "    with open(metrics_file, 'w') as f:\n",
    "        f.write(\"Epoch,Time(s),D_Loss,G_Loss,FID_Score\\n\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STARTING CGAN TRAINING - {num_epochs} EPOCHS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    for epoch in range(starting_epoch, num_epochs + 1):\n",
    "        epoch_start = time.time()\n",
    "        epoch_d_loss = 0\n",
    "        epoch_g_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for i, (imgs, labels) in enumerate(dataloader):\n",
    "            batch_size = imgs.size(0)\n",
    "            real_imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            real_labels = torch.ones(batch_size, 1).to(device) * 0.9\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device) + 0.1\n",
    "            \n",
    "            # Train Discriminator but skip training it every 3 epochs\n",
    "            if epoch % 3 == 0:\n",
    "                pass\n",
    "            else:\n",
    "                optimizer_D.zero_grad()\n",
    "                real_loss = criterion(discriminator(real_imgs, labels), real_labels)\n",
    "                \n",
    "                z = torch.randn(batch_size, latent_dim).to(device)\n",
    "                fake_imgs = generator(z, labels)\n",
    "                fake_loss = criterion(discriminator(fake_imgs.detach(), labels), fake_labels)\n",
    "                \n",
    "                d_loss = (real_loss + fake_loss) / 2\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "            \n",
    "            # Train Generator\n",
    "            optimizer_G.zero_grad()\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            gen_imgs = generator(z, labels)\n",
    "            g_loss = criterion(discriminator(gen_imgs, labels), real_labels)\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_d_loss = epoch_d_loss / num_batches\n",
    "        avg_g_loss = epoch_g_loss / num_batches\n",
    "        \n",
    "        # Calculate FID every 2 epochs\n",
    "        fid_score = 0.0\n",
    "        if epoch % 2 == 0:\n",
    "            with torch.no_grad():\n",
    "                real_batch = next(iter(dataloader))[0][:64].to(device)\n",
    "                z = torch.randn(64, latent_dim).to(device)\n",
    "                sample_labels = torch.full((64,), minority_class_idx, dtype=torch.long).to(device)\n",
    "                fake_batch = generator(z, sample_labels)\n",
    "                fid_score = calculate_fid(real_batch, fake_batch, device)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        print(f\"Epoch {epoch} | Time: {epoch_time:.2f}s\")\n",
    "        print(f\"  D_Loss: {avg_d_loss:.6f} | G_Loss: {avg_g_loss:.6f}\")\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"  FID Score: {fid_score:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        with open(metrics_file, 'a') as f:\n",
    "            f.write(f\"{epoch},{epoch_time:.2f},{avg_d_loss:.6f},{avg_g_loss:.6f},{fid_score:.4f}\\n\")\n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            save_sample_images(generator, epoch, latent_dim, save_path, labels=minority_class_idx)\n",
    "        \n",
    "        if epoch > 20 and epoch % 4 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'generator_state_dict': generator.state_dict(),\n",
    "                'discriminator_state_dict': discriminator.state_dict(),\n",
    "                'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "                'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "            }, f\"{model_path}/model_epoch_{epoch}.pt\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CGAN TRAINING COMPLETE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return generator, discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e3a31e",
   "metadata": {},
   "source": [
    "**Training Vanilla GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "586b8e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla Generator parameters: 3,834,624\n",
      "Vanilla Discriminator parameters: 3,803,137\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "latent_dim = 100\n",
    "\n",
    "# Initialize models\n",
    "vanilla_gen = VanillaGenerator(latent_dim=latent_dim, img_size=32).to(device)\n",
    "vanilla_disc = VanillaDiscriminator(img_size=32).to(device)\n",
    "\n",
    "print(f\"Vanilla Generator parameters: {sum(p.numel() for p in vanilla_gen.parameters()):,}\")\n",
    "print(f\"Vanilla Discriminator parameters: {sum(p.numel() for p in vanilla_disc.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e67aac7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING VANILLA GAN TRAINING - 100 EPOCHS\n",
      "================================================================================\n",
      "\n",
      "Epoch 1 | Time: 2.83s\n",
      "  D_Loss: 0.563648 | G_Loss: 0.772670\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_31756\\2722015332.py:28: DeprecationWarning: The `disp` argument is deprecated and will be removed in SciPy 1.18.0.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n",
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_31756\\2722015332.py:28: LinAlgWarning: Matrix is singular. The result might be inaccurate or the array might not have a square root.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Time: 11.49s\n",
      "  D_Loss: 0.623294 | G_Loss: 0.651922\n",
      "  FID Score: 363.4728\n",
      "\n",
      "Epoch 3 | Time: 2.02s\n",
      "  D_Loss: 0.608301 | G_Loss: 0.448395\n",
      "\n",
      "Epoch 4 | Time: 11.66s\n",
      "  D_Loss: 0.672562 | G_Loss: 0.718628\n",
      "  FID Score: 341.4000\n",
      "\n",
      "Epoch 5 | Time: 2.03s\n",
      "  D_Loss: 0.654959 | G_Loss: 0.634269\n",
      "\n",
      "Epoch 6 | Time: 15.39s\n",
      "  D_Loss: 0.636603 | G_Loss: 0.460647\n",
      "  FID Score: 290.8119\n",
      "\n",
      "Epoch 7 | Time: 2.40s\n",
      "  D_Loss: 0.655099 | G_Loss: 0.708532\n",
      "\n",
      "Epoch 8 | Time: 12.58s\n",
      "  D_Loss: 0.648440 | G_Loss: 0.688142\n",
      "  FID Score: 298.1932\n",
      "\n",
      "Epoch 9 | Time: 1.80s\n",
      "  D_Loss: 0.740177 | G_Loss: 0.499555\n",
      "\n",
      "Epoch 10 | Time: 15.00s\n",
      "  D_Loss: 0.632151 | G_Loss: 0.844523\n",
      "  FID Score: 299.8883\n",
      "\n",
      "Epoch 11 | Time: 2.06s\n",
      "  D_Loss: 0.637239 | G_Loss: 0.702686\n",
      "\n",
      "Epoch 12 | Time: 17.26s\n",
      "  D_Loss: 0.609468 | G_Loss: 0.483476\n",
      "  FID Score: 275.7558\n",
      "\n",
      "Epoch 13 | Time: 2.08s\n",
      "  D_Loss: 0.632367 | G_Loss: 0.760033\n",
      "\n",
      "Epoch 14 | Time: 16.02s\n",
      "  D_Loss: 0.619213 | G_Loss: 0.748934\n",
      "  FID Score: 274.6268\n",
      "\n",
      "Epoch 15 | Time: 1.81s\n",
      "  D_Loss: 0.564475 | G_Loss: 0.424947\n",
      "\n",
      "Epoch 16 | Time: 14.51s\n",
      "  D_Loss: 0.657835 | G_Loss: 0.879730\n",
      "  FID Score: 304.4354\n",
      "\n",
      "Epoch 17 | Time: 2.04s\n",
      "  D_Loss: 0.617611 | G_Loss: 0.745226\n",
      "\n",
      "Epoch 18 | Time: 14.95s\n",
      "  D_Loss: 0.591513 | G_Loss: 0.550504\n",
      "  FID Score: 278.2371\n",
      "\n",
      "Epoch 19 | Time: 2.00s\n",
      "  D_Loss: 0.641303 | G_Loss: 0.790126\n",
      "\n",
      "Epoch 20 | Time: 15.69s\n",
      "  D_Loss: 0.611966 | G_Loss: 0.765194\n",
      "  FID Score: 310.0321\n",
      "\n",
      "Epoch 21 | Time: 2.70s\n",
      "  D_Loss: 0.615991 | G_Loss: 0.587573\n",
      "\n",
      "Epoch 22 | Time: 12.65s\n",
      "  D_Loss: 0.600640 | G_Loss: 0.848866\n",
      "  FID Score: 297.7403\n",
      "\n",
      "Epoch 23 | Time: 2.26s\n",
      "  D_Loss: 0.588967 | G_Loss: 0.811158\n",
      "\n",
      "Epoch 24 | Time: 15.84s\n",
      "  D_Loss: 0.585475 | G_Loss: 0.524720\n",
      "  FID Score: 289.2415\n",
      "\n",
      "Epoch 25 | Time: 2.15s\n",
      "  D_Loss: 0.597111 | G_Loss: 0.902034\n",
      "\n",
      "Epoch 26 | Time: 16.99s\n",
      "  D_Loss: 0.568431 | G_Loss: 0.852701\n",
      "  FID Score: 294.1086\n",
      "\n",
      "Epoch 27 | Time: 1.86s\n",
      "  D_Loss: 0.545425 | G_Loss: 0.540808\n",
      "\n",
      "Epoch 28 | Time: 14.56s\n",
      "  D_Loss: 0.569058 | G_Loss: 1.046821\n",
      "  FID Score: 285.7790\n",
      "\n",
      "Epoch 29 | Time: 2.03s\n",
      "  D_Loss: 0.551569 | G_Loss: 0.917971\n",
      "\n",
      "Epoch 30 | Time: 15.77s\n",
      "  D_Loss: 0.498254 | G_Loss: 0.544271\n",
      "  FID Score: 292.7742\n",
      "\n",
      "Epoch 31 | Time: 2.26s\n",
      "  D_Loss: 0.604797 | G_Loss: 1.019522\n",
      "\n",
      "Epoch 32 | Time: 14.72s\n",
      "  D_Loss: 0.552575 | G_Loss: 0.898497\n",
      "  FID Score: 297.1882\n",
      "\n",
      "Epoch 33 | Time: 1.75s\n",
      "  D_Loss: 0.523103 | G_Loss: 0.643046\n",
      "\n",
      "Epoch 34 | Time: 14.58s\n",
      "  D_Loss: 0.538766 | G_Loss: 1.060459\n",
      "  FID Score: 290.5257\n",
      "\n",
      "Epoch 35 | Time: 2.04s\n",
      "  D_Loss: 0.538341 | G_Loss: 0.967973\n",
      "\n",
      "Epoch 36 | Time: 14.76s\n",
      "  D_Loss: 0.479965 | G_Loss: 0.708652\n",
      "  FID Score: 299.2510\n",
      "\n",
      "Epoch 37 | Time: 2.03s\n",
      "  D_Loss: 0.550660 | G_Loss: 1.082795\n",
      "\n",
      "Epoch 38 | Time: 15.10s\n",
      "  D_Loss: 0.514596 | G_Loss: 0.985150\n",
      "  FID Score: 298.7922\n",
      "\n",
      "Epoch 39 | Time: 1.77s\n",
      "  D_Loss: 0.492494 | G_Loss: 0.519040\n",
      "\n",
      "Epoch 40 | Time: 14.77s\n",
      "  D_Loss: 0.498316 | G_Loss: 1.164355\n",
      "  FID Score: 292.4520\n",
      "\n",
      "Epoch 41 | Time: 2.07s\n",
      "  D_Loss: 0.493489 | G_Loss: 1.061819\n",
      "\n",
      "Epoch 42 | Time: 15.00s\n",
      "  D_Loss: 0.459680 | G_Loss: 0.598024\n",
      "  FID Score: 293.8982\n",
      "\n",
      "Epoch 43 | Time: 2.08s\n",
      "  D_Loss: 0.488855 | G_Loss: 1.298936\n",
      "\n",
      "Epoch 44 | Time: 12.64s\n",
      "  D_Loss: 0.480396 | G_Loss: 1.104791\n",
      "  FID Score: 283.3226\n",
      "\n",
      "Epoch 45 | Time: 1.87s\n",
      "  D_Loss: 0.454989 | G_Loss: 0.649570\n",
      "\n",
      "Epoch 46 | Time: 14.72s\n",
      "  D_Loss: 0.469813 | G_Loss: 1.293955\n",
      "  FID Score: 295.4295\n",
      "\n",
      "Epoch 47 | Time: 2.44s\n",
      "  D_Loss: 0.474812 | G_Loss: 1.149029\n",
      "\n",
      "Epoch 48 | Time: 13.23s\n",
      "  D_Loss: 0.570133 | G_Loss: 0.751298\n",
      "  FID Score: 328.2898\n",
      "\n",
      "Epoch 49 | Time: 2.24s\n",
      "  D_Loss: 0.455786 | G_Loss: 1.420864\n",
      "\n",
      "Epoch 50 | Time: 12.27s\n",
      "  D_Loss: 0.460061 | G_Loss: 1.219682\n",
      "  FID Score: 292.1078\n",
      "\n",
      "Epoch 51 | Time: 1.92s\n",
      "  D_Loss: 0.417217 | G_Loss: 0.569230\n",
      "\n",
      "Epoch 52 | Time: 13.57s\n",
      "  D_Loss: 0.459441 | G_Loss: 1.384448\n",
      "  FID Score: 291.4671\n",
      "\n",
      "Epoch 53 | Time: 2.19s\n",
      "  D_Loss: 0.443536 | G_Loss: 1.257997\n",
      "\n",
      "Epoch 54 | Time: 15.79s\n",
      "  D_Loss: 0.447429 | G_Loss: 0.719436\n",
      "  FID Score: 319.6470\n",
      "\n",
      "Epoch 55 | Time: 2.07s\n",
      "  D_Loss: 0.422348 | G_Loss: 1.584975\n",
      "\n",
      "Epoch 56 | Time: 16.18s\n",
      "  D_Loss: 0.439096 | G_Loss: 1.333871\n",
      "  FID Score: 290.5484\n",
      "\n",
      "Epoch 57 | Time: 1.94s\n",
      "  D_Loss: 0.423937 | G_Loss: 0.684310\n",
      "\n",
      "Epoch 58 | Time: 15.45s\n",
      "  D_Loss: 0.422700 | G_Loss: 1.551513\n",
      "  FID Score: 302.7752\n",
      "\n",
      "Epoch 59 | Time: 2.09s\n",
      "  D_Loss: 0.426907 | G_Loss: 1.384449\n",
      "\n",
      "Epoch 60 | Time: 16.19s\n",
      "  D_Loss: 0.444339 | G_Loss: 0.754074\n",
      "  FID Score: 336.4916\n",
      "\n",
      "Epoch 61 | Time: 2.16s\n",
      "  D_Loss: 0.415062 | G_Loss: 1.559319\n",
      "\n",
      "Epoch 62 | Time: 16.75s\n",
      "  D_Loss: 0.425702 | G_Loss: 1.396420\n",
      "  FID Score: 296.3395\n",
      "\n",
      "Epoch 63 | Time: 2.02s\n",
      "  D_Loss: 0.376462 | G_Loss: 0.885327\n",
      "\n",
      "Epoch 64 | Time: 16.43s\n",
      "  D_Loss: 0.408042 | G_Loss: 1.729423\n",
      "  FID Score: 304.8249\n",
      "\n",
      "Epoch 65 | Time: 2.29s\n",
      "  D_Loss: 0.418661 | G_Loss: 1.438244\n",
      "\n",
      "Epoch 66 | Time: 16.51s\n",
      "  D_Loss: 0.437451 | G_Loss: 0.901426\n",
      "  FID Score: 305.7021\n",
      "\n",
      "Epoch 67 | Time: 2.57s\n",
      "  D_Loss: 0.401197 | G_Loss: 1.728269\n",
      "\n",
      "Epoch 68 | Time: 15.98s\n",
      "  D_Loss: 0.414692 | G_Loss: 1.495444\n",
      "  FID Score: 296.3881\n",
      "\n",
      "Epoch 69 | Time: 1.81s\n",
      "  D_Loss: 0.407241 | G_Loss: 0.833051\n",
      "\n",
      "Epoch 70 | Time: 16.38s\n",
      "  D_Loss: 0.426818 | G_Loss: 1.668996\n",
      "  FID Score: 302.1510\n",
      "\n",
      "Epoch 71 | Time: 2.11s\n",
      "  D_Loss: 0.419870 | G_Loss: 1.483849\n",
      "\n",
      "Epoch 72 | Time: 15.37s\n",
      "  D_Loss: 0.400294 | G_Loss: 0.831527\n",
      "  FID Score: 310.3591\n",
      "\n",
      "Epoch 73 | Time: 2.05s\n",
      "  D_Loss: 0.404455 | G_Loss: 1.751322\n",
      "\n",
      "Epoch 74 | Time: 15.79s\n",
      "  D_Loss: 0.415782 | G_Loss: 1.539842\n",
      "  FID Score: 296.5106\n",
      "\n",
      "Epoch 75 | Time: 2.03s\n",
      "  D_Loss: 0.444226 | G_Loss: 0.807439\n",
      "\n",
      "Epoch 76 | Time: 16.32s\n",
      "  D_Loss: 0.398798 | G_Loss: 1.683316\n",
      "  FID Score: 302.0665\n",
      "\n",
      "Epoch 77 | Time: 2.14s\n",
      "  D_Loss: 0.403638 | G_Loss: 1.546577\n",
      "\n",
      "Epoch 78 | Time: 11.26s\n",
      "  D_Loss: 0.400375 | G_Loss: 0.722888\n",
      "  FID Score: 320.8998\n",
      "\n",
      "Epoch 79 | Time: 2.12s\n",
      "  D_Loss: 0.400682 | G_Loss: 1.748140\n",
      "\n",
      "Epoch 80 | Time: 16.10s\n",
      "  D_Loss: 0.401152 | G_Loss: 1.583154\n",
      "  FID Score: 307.3320\n",
      "\n",
      "Epoch 81 | Time: 2.05s\n",
      "  D_Loss: 0.408248 | G_Loss: 0.733015\n",
      "\n",
      "Epoch 82 | Time: 14.79s\n",
      "  D_Loss: 0.393975 | G_Loss: 1.753440\n",
      "  FID Score: 297.0021\n",
      "\n",
      "Epoch 83 | Time: 2.12s\n",
      "  D_Loss: 0.404479 | G_Loss: 1.598734\n",
      "\n",
      "Epoch 84 | Time: 14.63s\n",
      "  D_Loss: 0.439867 | G_Loss: 0.850462\n",
      "  FID Score: 316.4258\n",
      "\n",
      "Epoch 85 | Time: 2.45s\n",
      "  D_Loss: 0.390176 | G_Loss: 1.781915\n",
      "\n",
      "Epoch 86 | Time: 14.02s\n",
      "  D_Loss: 0.401971 | G_Loss: 1.639918\n",
      "  FID Score: 290.0928\n",
      "\n",
      "Epoch 87 | Time: 1.85s\n",
      "  D_Loss: 0.382496 | G_Loss: 0.965544\n",
      "\n",
      "Epoch 88 | Time: 15.08s\n",
      "  D_Loss: 0.393899 | G_Loss: 1.766239\n",
      "  FID Score: 309.3879\n",
      "\n",
      "Epoch 89 | Time: 2.10s\n",
      "  D_Loss: 0.395318 | G_Loss: 1.612248\n",
      "\n",
      "Epoch 90 | Time: 16.15s\n",
      "  D_Loss: 0.397504 | G_Loss: 0.635159\n",
      "  FID Score: 309.1028\n",
      "\n",
      "Epoch 91 | Time: 2.15s\n",
      "  D_Loss: 0.408767 | G_Loss: 1.681689\n",
      "\n",
      "Epoch 92 | Time: 14.99s\n",
      "  D_Loss: 0.397222 | G_Loss: 1.628106\n",
      "  FID Score: 299.8175\n",
      "\n",
      "Epoch 93 | Time: 1.83s\n",
      "  D_Loss: 0.394882 | G_Loss: 0.751219\n",
      "\n",
      "Epoch 94 | Time: 14.34s\n",
      "  D_Loss: 0.394447 | G_Loss: 1.753233\n",
      "  FID Score: 317.9962\n",
      "\n",
      "Epoch 95 | Time: 2.15s\n",
      "  D_Loss: 0.390779 | G_Loss: 1.661002\n",
      "\n",
      "Epoch 96 | Time: 15.54s\n",
      "  D_Loss: 0.391830 | G_Loss: 0.761397\n",
      "  FID Score: 335.8478\n",
      "\n",
      "Epoch 97 | Time: 2.05s\n",
      "  D_Loss: 0.402835 | G_Loss: 1.781331\n",
      "\n",
      "Epoch 98 | Time: 12.09s\n",
      "  D_Loss: 0.389851 | G_Loss: 1.650875\n",
      "  FID Score: 303.2319\n",
      "\n",
      "Epoch 99 | Time: 2.01s\n",
      "  D_Loss: 0.387502 | G_Loss: 1.053641\n",
      "\n",
      "Epoch 100 | Time: 15.28s\n",
      "  D_Loss: 0.384123 | G_Loss: 1.833423\n",
      "  FID Score: 292.2245\n",
      "\n",
      "\n",
      "================================================================================\n",
      "VANILLA GAN TRAINING COMPLETE\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Vanilla GAN\n",
    "num_epochs = 100\n",
    "vanilla_gen, vanilla_disc = train_vanilla_gan(\n",
    "    vanilla_gen, \n",
    "    vanilla_disc, \n",
    "    minority_loader, \n",
    "    num_epochs=num_epochs,\n",
    "    latent_dim=latent_dim,\n",
    "    save_path='generated_images/vanilla_gan',\n",
    "    model_path='models/vanilla_gan'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f91818",
   "metadata": {},
   "source": [
    "The best Epoch is 70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b744f4f3",
   "metadata": {},
   "source": [
    "**Training DCGAN GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f8a147a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DCGAN Generator parameters: 1,073,219\n",
      "DCGAN Discriminator parameters: 663,745\n"
     ]
    }
   ],
   "source": [
    "# Initialize DCGAN\n",
    "dcgan_gen = DCGANGenerator(latent_dim=latent_dim).to(device)\n",
    "dcgan_disc = DCGANDiscriminator().to(device)\n",
    "\n",
    "print(f\"\\nDCGAN Generator parameters: {sum(p.numel() for p in dcgan_gen.parameters()):,}\")\n",
    "print(f\"DCGAN Discriminator parameters: {sum(p.numel() for p in dcgan_disc.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cb58553b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING DCGAN TRAINING - 100 EPOCHS\n",
      "================================================================================\n",
      "\n",
      "Epoch 1 | Time: 2.30s\n",
      "  D_Loss: 0.343217 | G_Loss: 2.137417\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_31756\\2722015332.py:28: DeprecationWarning: The `disp` argument is deprecated and will be removed in SciPy 1.18.0.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n",
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_31756\\2722015332.py:28: LinAlgWarning: Matrix is singular. The result might be inaccurate or the array might not have a square root.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Time: 12.59s\n",
      "  D_Loss: 0.336926 | G_Loss: 2.260074\n",
      "  FID Score: 396.4155\n",
      "\n",
      "Epoch 3 | Time: 2.05s\n",
      "  D_Loss: 0.331577 | G_Loss: 0.612319\n",
      "\n",
      "Epoch 4 | Time: 16.46s\n",
      "  D_Loss: 0.382754 | G_Loss: 2.212358\n",
      "  FID Score: 332.5704\n",
      "\n",
      "Epoch 5 | Time: 2.36s\n",
      "  D_Loss: 0.340544 | G_Loss: 2.161172\n",
      "\n",
      "Epoch 6 | Time: 14.85s\n",
      "  D_Loss: 0.344709 | G_Loss: 0.696294\n",
      "  FID Score: 337.6371\n",
      "\n",
      "Epoch 7 | Time: 2.41s\n",
      "  D_Loss: 0.410165 | G_Loss: 2.066207\n",
      "\n",
      "Epoch 8 | Time: 15.81s\n",
      "  D_Loss: 0.338833 | G_Loss: 2.141226\n",
      "  FID Score: 358.2674\n",
      "\n",
      "Epoch 9 | Time: 1.88s\n",
      "  D_Loss: 0.331256 | G_Loss: 0.854641\n",
      "\n",
      "Epoch 10 | Time: 15.98s\n",
      "  D_Loss: 0.391039 | G_Loss: 2.178513\n",
      "  FID Score: 336.2652\n",
      "\n",
      "Epoch 11 | Time: 2.42s\n",
      "  D_Loss: 0.331997 | G_Loss: 2.129127\n",
      "\n",
      "Epoch 12 | Time: 12.75s\n",
      "  D_Loss: 0.335409 | G_Loss: 1.297927\n",
      "  FID Score: 345.8259\n",
      "\n",
      "Epoch 13 | Time: 2.43s\n",
      "  D_Loss: 0.366114 | G_Loss: 2.180859\n",
      "\n",
      "Epoch 14 | Time: 12.10s\n",
      "  D_Loss: 0.333842 | G_Loss: 2.114694\n",
      "  FID Score: 303.4907\n",
      "\n",
      "Epoch 15 | Time: 1.94s\n",
      "  D_Loss: 0.362843 | G_Loss: 0.774428\n",
      "\n",
      "Epoch 16 | Time: 13.82s\n",
      "  D_Loss: 0.373744 | G_Loss: 2.152148\n",
      "  FID Score: 329.6765\n",
      "\n",
      "Epoch 17 | Time: 2.68s\n",
      "  D_Loss: 0.329528 | G_Loss: 2.142797\n",
      "\n",
      "Epoch 18 | Time: 16.19s\n",
      "  D_Loss: 0.327623 | G_Loss: 1.015994\n",
      "  FID Score: 270.7285\n",
      "\n",
      "Epoch 19 | Time: 3.96s\n",
      "  D_Loss: 0.365796 | G_Loss: 2.168802\n",
      "\n",
      "Epoch 20 | Time: 11.90s\n",
      "  D_Loss: 0.330099 | G_Loss: 2.113541\n",
      "  FID Score: 328.7135\n",
      "\n",
      "Epoch 21 | Time: 2.00s\n",
      "  D_Loss: 0.329496 | G_Loss: 0.964884\n",
      "\n",
      "Epoch 22 | Time: 13.26s\n",
      "  D_Loss: 0.359066 | G_Loss: 2.223482\n",
      "  FID Score: 305.9557\n",
      "\n",
      "Epoch 23 | Time: 2.44s\n",
      "  D_Loss: 0.328664 | G_Loss: 2.114978\n",
      "\n",
      "Epoch 24 | Time: 15.57s\n",
      "  D_Loss: 0.327629 | G_Loss: 1.553351\n",
      "  FID Score: 267.0763\n",
      "\n",
      "Epoch 25 | Time: 4.00s\n",
      "  D_Loss: 0.333541 | G_Loss: 2.115165\n",
      "\n",
      "Epoch 26 | Time: 12.90s\n",
      "  D_Loss: 0.327466 | G_Loss: 2.115552\n",
      "  FID Score: 285.3707\n",
      "\n",
      "Epoch 27 | Time: 1.88s\n",
      "  D_Loss: 0.327618 | G_Loss: 1.230230\n",
      "\n",
      "Epoch 28 | Time: 14.59s\n",
      "  D_Loss: 0.348699 | G_Loss: 2.249310\n",
      "  FID Score: 290.9474\n",
      "\n",
      "Epoch 29 | Time: 2.27s\n",
      "  D_Loss: 0.328322 | G_Loss: 2.124040\n",
      "\n",
      "Epoch 30 | Time: 15.40s\n",
      "  D_Loss: 0.327074 | G_Loss: 1.304054\n",
      "  FID Score: 329.9123\n",
      "\n",
      "Epoch 31 | Time: 2.18s\n",
      "  D_Loss: 0.352914 | G_Loss: 2.238501\n",
      "\n",
      "Epoch 32 | Time: 15.15s\n",
      "  D_Loss: 0.329744 | G_Loss: 2.120444\n",
      "  FID Score: 287.0640\n",
      "\n",
      "Epoch 33 | Time: 3.79s\n",
      "  D_Loss: 0.327956 | G_Loss: 1.372961\n",
      "\n",
      "Epoch 34 | Time: 15.80s\n",
      "  D_Loss: 0.332324 | G_Loss: 2.147312\n",
      "  FID Score: 300.9016\n",
      "\n",
      "Epoch 35 | Time: 2.49s\n",
      "  D_Loss: 0.326867 | G_Loss: 2.093053\n",
      "\n",
      "Epoch 36 | Time: 14.53s\n",
      "  D_Loss: 0.327772 | G_Loss: 1.506654\n",
      "  FID Score: 278.2126\n",
      "\n",
      "Epoch 37 | Time: 2.27s\n",
      "  D_Loss: 0.336368 | G_Loss: 2.175613\n",
      "\n",
      "Epoch 38 | Time: 15.35s\n",
      "  D_Loss: 0.326385 | G_Loss: 2.075210\n",
      "  FID Score: 288.1416\n",
      "\n",
      "Epoch 39 | Time: 1.92s\n",
      "  D_Loss: 0.326995 | G_Loss: 1.656409\n",
      "\n",
      "Epoch 40 | Time: 14.89s\n",
      "  D_Loss: 0.331769 | G_Loss: 2.155369\n",
      "  FID Score: 307.2753\n",
      "\n",
      "Epoch 41 | Time: 2.16s\n",
      "  D_Loss: 0.327799 | G_Loss: 2.090972\n",
      "\n",
      "Epoch 42 | Time: 12.21s\n",
      "  D_Loss: 0.325894 | G_Loss: 1.714830\n",
      "  FID Score: 297.4226\n",
      "\n",
      "Epoch 43 | Time: 2.23s\n",
      "  D_Loss: 0.328489 | G_Loss: 2.109024\n",
      "\n",
      "Epoch 44 | Time: 15.72s\n",
      "  D_Loss: 0.326858 | G_Loss: 2.091974\n",
      "  FID Score: 276.5269\n",
      "\n",
      "Epoch 45 | Time: 2.57s\n",
      "  D_Loss: 0.325680 | G_Loss: 1.627574\n",
      "\n",
      "Epoch 46 | Time: 15.34s\n",
      "  D_Loss: 0.329672 | G_Loss: 2.121644\n",
      "  FID Score: 311.8793\n",
      "\n",
      "Epoch 47 | Time: 2.11s\n",
      "  D_Loss: 0.326330 | G_Loss: 2.095119\n",
      "\n",
      "Epoch 48 | Time: 15.64s\n",
      "  D_Loss: 0.328166 | G_Loss: 1.755069\n",
      "  FID Score: 304.5668\n",
      "\n",
      "Epoch 49 | Time: 2.14s\n",
      "  D_Loss: 0.327971 | G_Loss: 2.109087\n",
      "\n",
      "Epoch 50 | Time: 17.00s\n",
      "  D_Loss: 0.326403 | G_Loss: 2.091830\n",
      "  FID Score: 301.9480\n",
      "\n",
      "Epoch 51 | Time: 1.85s\n",
      "  D_Loss: 0.327199 | G_Loss: 1.749265\n",
      "\n",
      "Epoch 52 | Time: 14.80s\n",
      "  D_Loss: 0.330053 | G_Loss: 2.166515\n",
      "  FID Score: 338.4242\n",
      "\n",
      "Epoch 53 | Time: 2.05s\n",
      "  D_Loss: 0.326170 | G_Loss: 2.103091\n",
      "\n",
      "Epoch 54 | Time: 13.78s\n",
      "  D_Loss: 0.325384 | G_Loss: 1.209838\n",
      "  FID Score: 346.7172\n",
      "\n",
      "Epoch 55 | Time: 2.04s\n",
      "  D_Loss: 0.352402 | G_Loss: 2.463166\n",
      "\n",
      "Epoch 56 | Time: 14.05s\n",
      "  D_Loss: 0.326465 | G_Loss: 2.115095\n",
      "  FID Score: 322.1432\n",
      "\n",
      "Epoch 57 | Time: 1.86s\n",
      "  D_Loss: 0.327113 | G_Loss: 0.718304\n",
      "\n",
      "Epoch 58 | Time: 11.21s\n",
      "  D_Loss: 0.376343 | G_Loss: 2.209365\n",
      "  FID Score: 281.7280\n",
      "\n",
      "Epoch 59 | Time: 2.11s\n",
      "  D_Loss: 0.328800 | G_Loss: 2.149981\n",
      "\n",
      "Epoch 60 | Time: 13.60s\n",
      "  D_Loss: 0.329814 | G_Loss: 1.259838\n",
      "  FID Score: 309.4073\n",
      "\n",
      "Epoch 61 | Time: 3.97s\n",
      "  D_Loss: 0.368082 | G_Loss: 2.417028\n",
      "\n",
      "Epoch 62 | Time: 14.66s\n",
      "  D_Loss: 0.327865 | G_Loss: 2.146256\n",
      "  FID Score: 336.5211\n",
      "\n",
      "Epoch 63 | Time: 1.80s\n",
      "  D_Loss: 0.325857 | G_Loss: 1.006082\n",
      "\n",
      "Epoch 64 | Time: 14.67s\n",
      "  D_Loss: 0.372733 | G_Loss: 2.291564\n",
      "  FID Score: 327.0137\n",
      "\n",
      "Epoch 65 | Time: 2.05s\n",
      "  D_Loss: 0.331650 | G_Loss: 2.145913\n",
      "\n",
      "Epoch 66 | Time: 13.85s\n",
      "  D_Loss: 0.331978 | G_Loss: 1.215595\n",
      "  FID Score: 307.7437\n",
      "\n",
      "Epoch 67 | Time: 2.06s\n",
      "  D_Loss: 0.364693 | G_Loss: 2.220413\n",
      "\n",
      "Epoch 68 | Time: 14.32s\n",
      "  D_Loss: 0.328831 | G_Loss: 2.108166\n",
      "  FID Score: 272.8100\n",
      "\n",
      "Epoch 69 | Time: 1.76s\n",
      "  D_Loss: 0.328885 | G_Loss: 1.461940\n",
      "\n",
      "Epoch 70 | Time: 14.31s\n",
      "  D_Loss: 0.332828 | G_Loss: 2.142805\n",
      "  FID Score: 331.4224\n",
      "\n",
      "Epoch 71 | Time: 2.08s\n",
      "  D_Loss: 0.326540 | G_Loss: 2.073560\n",
      "\n",
      "Epoch 72 | Time: 14.01s\n",
      "  D_Loss: 0.326435 | G_Loss: 1.210161\n",
      "  FID Score: 312.6977\n",
      "\n",
      "Epoch 73 | Time: 2.17s\n",
      "  D_Loss: 0.345758 | G_Loss: 2.256794\n",
      "\n",
      "Epoch 74 | Time: 11.68s\n",
      "  D_Loss: 0.327784 | G_Loss: 2.104622\n",
      "  FID Score: 347.1239\n",
      "\n",
      "Epoch 75 | Time: 1.91s\n",
      "  D_Loss: 0.328076 | G_Loss: 1.896425\n",
      "\n",
      "Epoch 76 | Time: 12.68s\n",
      "  D_Loss: 0.327786 | G_Loss: 2.087339\n",
      "  FID Score: 303.7060\n",
      "\n",
      "Epoch 77 | Time: 2.07s\n",
      "  D_Loss: 0.326135 | G_Loss: 2.077284\n",
      "\n",
      "Epoch 78 | Time: 14.73s\n",
      "  D_Loss: 0.325658 | G_Loss: 1.798081\n",
      "  FID Score: 330.5174\n",
      "\n",
      "Epoch 79 | Time: 3.78s\n",
      "  D_Loss: 0.327476 | G_Loss: 2.094564\n",
      "\n",
      "Epoch 80 | Time: 14.87s\n",
      "  D_Loss: 0.326152 | G_Loss: 2.088178\n",
      "  FID Score: 311.9419\n",
      "\n",
      "Epoch 81 | Time: 1.77s\n",
      "  D_Loss: 0.325975 | G_Loss: 1.282345\n",
      "\n",
      "Epoch 82 | Time: 13.99s\n",
      "  D_Loss: 0.343197 | G_Loss: 2.228561\n",
      "  FID Score: 317.8579\n",
      "\n",
      "Epoch 83 | Time: 4.00s\n",
      "  D_Loss: 0.326100 | G_Loss: 2.104631\n",
      "\n",
      "Epoch 84 | Time: 13.62s\n",
      "  D_Loss: 0.326472 | G_Loss: 0.962933\n",
      "  FID Score: 331.3954\n",
      "\n",
      "Epoch 85 | Time: 2.08s\n",
      "  D_Loss: 0.348971 | G_Loss: 2.254763\n",
      "\n",
      "Epoch 86 | Time: 14.65s\n",
      "  D_Loss: 0.326672 | G_Loss: 2.112959\n",
      "  FID Score: 417.2122\n",
      "\n",
      "Epoch 87 | Time: 1.83s\n",
      "  D_Loss: 0.331276 | G_Loss: 1.347837\n",
      "\n",
      "Epoch 88 | Time: 14.41s\n",
      "  D_Loss: 0.345628 | G_Loss: 2.189866\n",
      "  FID Score: 324.4791\n",
      "\n",
      "Epoch 89 | Time: 2.06s\n",
      "  D_Loss: 0.328476 | G_Loss: 2.114323\n",
      "\n",
      "Epoch 90 | Time: 10.82s\n",
      "  D_Loss: 0.326596 | G_Loss: 1.621139\n",
      "  FID Score: 317.5771\n",
      "\n",
      "Epoch 91 | Time: 2.08s\n",
      "  D_Loss: 0.329594 | G_Loss: 2.115011\n",
      "\n",
      "Epoch 92 | Time: 14.46s\n",
      "  D_Loss: 0.326097 | G_Loss: 2.083905\n",
      "  FID Score: 336.2301\n",
      "\n",
      "Epoch 93 | Time: 1.81s\n",
      "  D_Loss: 0.325754 | G_Loss: 1.852972\n",
      "\n",
      "Epoch 94 | Time: 14.46s\n",
      "  D_Loss: 0.326632 | G_Loss: 2.095628\n",
      "  FID Score: 345.0522\n",
      "\n",
      "Epoch 95 | Time: 2.09s\n",
      "  D_Loss: 0.325931 | G_Loss: 2.084257\n",
      "\n",
      "Epoch 96 | Time: 14.33s\n",
      "  D_Loss: 0.327697 | G_Loss: 1.710955\n",
      "  FID Score: 357.0564\n",
      "\n",
      "Epoch 97 | Time: 2.05s\n",
      "  D_Loss: 0.326649 | G_Loss: 2.088993\n",
      "\n",
      "Epoch 98 | Time: 14.37s\n",
      "  D_Loss: 0.325820 | G_Loss: 2.090105\n",
      "  FID Score: 356.5583\n",
      "\n",
      "Epoch 99 | Time: 1.79s\n",
      "  D_Loss: 0.325299 | G_Loss: 1.624389\n",
      "\n",
      "Epoch 100 | Time: 14.62s\n",
      "  D_Loss: 0.329454 | G_Loss: 2.141216\n",
      "  FID Score: 379.8259\n",
      "\n",
      "\n",
      "================================================================================\n",
      "DCGAN TRAINING COMPLETE\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dcgan_gen, dcgan_disc = train_dcgan(\n",
    "    dcgan_gen,\n",
    "    dcgan_disc,\n",
    "    minority_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    latent_dim=latent_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e7a09",
   "metadata": {},
   "source": [
    "epoch 44 is the best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9202ff2a",
   "metadata": {},
   "source": [
    "**Training CGAN GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0eb54998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CGAN Generator parameters: 8,139,055\n",
      "CGAN Discriminator parameters: 2,764,481\n"
     ]
    }
   ],
   "source": [
    "# Initialize CGAN\n",
    "num_classes = len(class_names)\n",
    "cgan_gen = CGANGenerator(latent_dim=latent_dim, num_classes=num_classes).to(device)\n",
    "cgan_disc = CGANDiscriminator(num_classes=num_classes).to(device)\n",
    "\n",
    "print(f\"\\nCGAN Generator parameters: {sum(p.numel() for p in cgan_gen.parameters()):,}\")\n",
    "print(f\"CGAN Discriminator parameters: {sum(p.numel() for p in cgan_disc.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d0e2e90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING CGAN TRAINING - 100 EPOCHS\n",
      "================================================================================\n",
      "\n",
      "Epoch 1 | Time: 3.04s\n",
      "  D_Loss: 0.376349 | G_Loss: 2.331968\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_31756\\2722015332.py:28: DeprecationWarning: The `disp` argument is deprecated and will be removed in SciPy 1.18.0.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n",
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_31756\\2722015332.py:28: LinAlgWarning: Matrix is singular. The result might be inaccurate or the array might not have a square root.\n",
      "  covmean, _ = linalg.sqrtm(sigma_real.dot(sigma_fake), disp=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Time: 13.63s\n",
      "  D_Loss: 0.333416 | G_Loss: 2.195502\n",
      "  FID Score: 409.1740\n",
      "\n",
      "Epoch 3 | Time: 2.62s\n",
      "  D_Loss: 0.349897 | G_Loss: 1.647663\n",
      "\n",
      "Epoch 4 | Time: 14.15s\n",
      "  D_Loss: 0.382518 | G_Loss: 2.276863\n",
      "  FID Score: 383.0750\n",
      "\n",
      "Epoch 5 | Time: 4.81s\n",
      "  D_Loss: 0.335652 | G_Loss: 2.134740\n",
      "\n",
      "Epoch 6 | Time: 13.84s\n",
      "  D_Loss: 0.453542 | G_Loss: 0.378009\n",
      "  FID Score: 399.9601\n",
      "\n",
      "Epoch 7 | Time: 3.17s\n",
      "  D_Loss: 0.439584 | G_Loss: 1.988269\n",
      "\n",
      "Epoch 8 | Time: 13.52s\n",
      "  D_Loss: 0.327505 | G_Loss: 2.062441\n",
      "  FID Score: 388.2015\n",
      "\n",
      "Epoch 9 | Time: 2.93s\n",
      "  D_Loss: 0.325385 | G_Loss: 1.027799\n",
      "\n",
      "Epoch 10 | Time: 14.22s\n",
      "  D_Loss: 0.387209 | G_Loss: 1.998247\n",
      "  FID Score: 397.3696\n",
      "\n",
      "Epoch 11 | Time: 3.29s\n",
      "  D_Loss: 0.328229 | G_Loss: 2.075007\n",
      "\n",
      "Epoch 12 | Time: 14.32s\n",
      "  D_Loss: 0.327045 | G_Loss: 1.502221\n",
      "  FID Score: 436.4069\n",
      "\n",
      "Epoch 13 | Time: 3.23s\n",
      "  D_Loss: 0.345077 | G_Loss: 2.097829\n",
      "\n",
      "Epoch 14 | Time: 14.28s\n",
      "  D_Loss: 0.326540 | G_Loss: 2.071369\n",
      "  FID Score: 413.4449\n",
      "\n",
      "Epoch 15 | Time: 2.70s\n",
      "  D_Loss: 0.327266 | G_Loss: 1.762367\n",
      "\n",
      "Epoch 16 | Time: 12.70s\n",
      "  D_Loss: 0.327470 | G_Loss: 2.089786\n",
      "  FID Score: 425.5453\n",
      "\n",
      "Epoch 17 | Time: 2.89s\n",
      "  D_Loss: 0.326167 | G_Loss: 2.078554\n",
      "\n",
      "Epoch 18 | Time: 13.44s\n",
      "  D_Loss: 0.325597 | G_Loss: 2.000306\n",
      "  FID Score: 464.3637\n",
      "\n",
      "Epoch 19 | Time: 5.14s\n",
      "  D_Loss: 0.325975 | G_Loss: 2.090656\n",
      "\n",
      "Epoch 20 | Time: 17.01s\n",
      "  D_Loss: 0.325682 | G_Loss: 2.079684\n",
      "  FID Score: 484.0596\n",
      "\n",
      "Epoch 21 | Time: 3.58s\n",
      "  D_Loss: 0.326253 | G_Loss: 1.805333\n",
      "\n",
      "Epoch 22 | Time: 13.62s\n",
      "  D_Loss: 0.326139 | G_Loss: 2.103147\n",
      "  FID Score: 487.8508\n",
      "\n",
      "Epoch 23 | Time: 2.80s\n",
      "  D_Loss: 0.325769 | G_Loss: 2.079509\n",
      "\n",
      "Epoch 24 | Time: 16.65s\n",
      "  D_Loss: 0.325947 | G_Loss: 1.886196\n",
      "  FID Score: 457.5462\n",
      "\n",
      "Epoch 25 | Time: 3.13s\n",
      "  D_Loss: 0.325805 | G_Loss: 2.095247\n",
      "\n",
      "Epoch 26 | Time: 13.21s\n",
      "  D_Loss: 0.325518 | G_Loss: 2.085389\n",
      "  FID Score: 454.5918\n",
      "\n",
      "Epoch 27 | Time: 2.48s\n",
      "  D_Loss: 0.325278 | G_Loss: 1.954040\n",
      "\n",
      "Epoch 28 | Time: 16.11s\n",
      "  D_Loss: 0.325658 | G_Loss: 2.085467\n",
      "  FID Score: 457.3370\n",
      "\n",
      "Epoch 29 | Time: 3.06s\n",
      "  D_Loss: 0.325484 | G_Loss: 2.080526\n",
      "\n",
      "Epoch 30 | Time: 16.48s\n",
      "  D_Loss: 0.326754 | G_Loss: 1.963177\n",
      "  FID Score: 445.1766\n",
      "\n",
      "Epoch 31 | Time: 3.06s\n",
      "  D_Loss: 0.325432 | G_Loss: 2.086826\n",
      "\n",
      "Epoch 32 | Time: 16.36s\n",
      "  D_Loss: 0.325372 | G_Loss: 2.082364\n",
      "  FID Score: 433.0051\n",
      "\n",
      "Epoch 33 | Time: 2.46s\n",
      "  D_Loss: 0.325201 | G_Loss: 1.979366\n",
      "\n",
      "Epoch 34 | Time: 16.44s\n",
      "  D_Loss: 0.325449 | G_Loss: 2.092375\n",
      "  FID Score: 463.1146\n",
      "\n",
      "Epoch 35 | Time: 4.16s\n",
      "  D_Loss: 0.325497 | G_Loss: 2.087904\n",
      "\n",
      "Epoch 36 | Time: 14.49s\n",
      "  D_Loss: 0.325563 | G_Loss: 2.052341\n",
      "  FID Score: 458.3723\n",
      "\n",
      "Epoch 37 | Time: 2.72s\n",
      "  D_Loss: 0.325390 | G_Loss: 2.087965\n",
      "\n",
      "Epoch 38 | Time: 11.60s\n",
      "  D_Loss: 0.325353 | G_Loss: 2.077654\n",
      "  FID Score: 468.6566\n",
      "\n",
      "Epoch 39 | Time: 2.36s\n",
      "  D_Loss: 0.325461 | G_Loss: 1.960304\n",
      "\n",
      "Epoch 40 | Time: 14.87s\n",
      "  D_Loss: 0.325361 | G_Loss: 2.085548\n",
      "  FID Score: 446.8474\n",
      "\n",
      "Epoch 41 | Time: 2.70s\n",
      "  D_Loss: 0.325248 | G_Loss: 2.076325\n",
      "\n",
      "Epoch 42 | Time: 11.35s\n",
      "  D_Loss: 0.325108 | G_Loss: 2.031939\n",
      "  FID Score: 458.9256\n",
      "\n",
      "Epoch 43 | Time: 2.72s\n",
      "  D_Loss: 0.325290 | G_Loss: 2.087257\n",
      "\n",
      "Epoch 44 | Time: 15.08s\n",
      "  D_Loss: 0.325242 | G_Loss: 2.080196\n",
      "  FID Score: 481.7861\n",
      "\n",
      "Epoch 45 | Time: 2.44s\n",
      "  D_Loss: 0.325295 | G_Loss: 2.047458\n",
      "\n",
      "Epoch 46 | Time: 11.99s\n",
      "  D_Loss: 0.325238 | G_Loss: 2.082381\n",
      "  FID Score: 462.9300\n",
      "\n",
      "Epoch 47 | Time: 2.76s\n",
      "  D_Loss: 0.325212 | G_Loss: 2.082995\n",
      "\n",
      "Epoch 48 | Time: 14.45s\n",
      "  D_Loss: 0.325294 | G_Loss: 2.058980\n",
      "  FID Score: 465.5988\n",
      "\n",
      "Epoch 49 | Time: 3.45s\n",
      "  D_Loss: 0.325244 | G_Loss: 2.088454\n",
      "\n",
      "Epoch 50 | Time: 14.91s\n",
      "  D_Loss: 0.325206 | G_Loss: 2.082488\n",
      "  FID Score: 466.8810\n",
      "\n",
      "Epoch 51 | Time: 2.43s\n",
      "  D_Loss: 0.325170 | G_Loss: 2.016611\n",
      "\n",
      "Epoch 52 | Time: 15.97s\n",
      "  D_Loss: 0.325260 | G_Loss: 2.085594\n",
      "  FID Score: 485.6526\n",
      "\n",
      "Epoch 53 | Time: 2.71s\n",
      "  D_Loss: 0.325213 | G_Loss: 2.085265\n",
      "\n",
      "Epoch 54 | Time: 11.25s\n",
      "  D_Loss: 0.325276 | G_Loss: 2.031226\n",
      "  FID Score: 477.5043\n",
      "\n",
      "Epoch 55 | Time: 2.74s\n",
      "  D_Loss: 0.325226 | G_Loss: 2.085573\n",
      "\n",
      "Epoch 56 | Time: 14.68s\n",
      "  D_Loss: 0.325259 | G_Loss: 2.083372\n",
      "  FID Score: 477.6538\n",
      "\n",
      "Epoch 57 | Time: 2.37s\n",
      "  D_Loss: 0.325202 | G_Loss: 2.055961\n",
      "\n",
      "Epoch 58 | Time: 12.75s\n",
      "  D_Loss: 0.325196 | G_Loss: 2.086213\n",
      "  FID Score: 473.6088\n",
      "\n",
      "Epoch 59 | Time: 3.20s\n",
      "  D_Loss: 0.325245 | G_Loss: 2.087969\n",
      "\n",
      "Epoch 60 | Time: 12.53s\n",
      "  D_Loss: 0.325235 | G_Loss: 2.033274\n",
      "  FID Score: 451.9984\n",
      "\n",
      "Epoch 61 | Time: 2.90s\n",
      "  D_Loss: 0.325450 | G_Loss: 2.084157\n",
      "\n",
      "Epoch 62 | Time: 14.23s\n",
      "  D_Loss: 0.325260 | G_Loss: 2.083131\n",
      "  FID Score: 469.7599\n",
      "\n",
      "Epoch 63 | Time: 2.37s\n",
      "  D_Loss: 0.325195 | G_Loss: 2.088162\n",
      "\n",
      "Epoch 64 | Time: 15.17s\n",
      "  D_Loss: 0.325219 | G_Loss: 2.084928\n",
      "  FID Score: 464.8016\n",
      "\n",
      "Epoch 65 | Time: 2.71s\n",
      "  D_Loss: 0.325176 | G_Loss: 2.085430\n",
      "\n",
      "Epoch 66 | Time: 11.20s\n",
      "  D_Loss: 0.325162 | G_Loss: 2.082632\n",
      "  FID Score: 446.5827\n",
      "\n",
      "Epoch 67 | Time: 2.74s\n",
      "  D_Loss: 0.325206 | G_Loss: 2.085503\n",
      "\n",
      "Epoch 68 | Time: 15.76s\n",
      "  D_Loss: 0.325175 | G_Loss: 2.082070\n",
      "  FID Score: 437.4395\n",
      "\n",
      "Epoch 69 | Time: 2.33s\n",
      "  D_Loss: 0.325130 | G_Loss: 2.060146\n",
      "\n",
      "Epoch 70 | Time: 15.44s\n",
      "  D_Loss: 0.325208 | G_Loss: 2.084193\n",
      "  FID Score: 449.3758\n",
      "\n",
      "Epoch 71 | Time: 2.96s\n",
      "  D_Loss: 0.325169 | G_Loss: 2.086105\n",
      "\n",
      "Epoch 72 | Time: 14.26s\n",
      "  D_Loss: 0.325135 | G_Loss: 2.088660\n",
      "  FID Score: 446.7274\n",
      "\n",
      "Epoch 73 | Time: 2.89s\n",
      "  D_Loss: 0.325176 | G_Loss: 2.085297\n",
      "\n",
      "Epoch 74 | Time: 13.21s\n",
      "  D_Loss: 0.325239 | G_Loss: 2.084217\n",
      "  FID Score: 441.5742\n",
      "\n",
      "Epoch 75 | Time: 2.49s\n",
      "  D_Loss: 0.325214 | G_Loss: 2.070644\n",
      "\n",
      "Epoch 76 | Time: 16.70s\n",
      "  D_Loss: 0.325176 | G_Loss: 2.085477\n",
      "  FID Score: 439.9264\n",
      "\n",
      "Epoch 77 | Time: 2.94s\n",
      "  D_Loss: 0.325256 | G_Loss: 2.085367\n",
      "\n",
      "Epoch 78 | Time: 13.29s\n",
      "  D_Loss: 0.325116 | G_Loss: 1.983993\n",
      "  FID Score: 453.0714\n",
      "\n",
      "Epoch 79 | Time: 2.74s\n",
      "  D_Loss: 0.325233 | G_Loss: 2.086590\n",
      "\n",
      "Epoch 80 | Time: 13.22s\n",
      "  D_Loss: 0.325201 | G_Loss: 2.084521\n",
      "  FID Score: 460.3079\n",
      "\n",
      "Epoch 81 | Time: 2.36s\n",
      "  D_Loss: 0.325239 | G_Loss: 2.080456\n",
      "\n",
      "Epoch 82 | Time: 12.32s\n",
      "  D_Loss: 0.325185 | G_Loss: 2.083916\n",
      "  FID Score: 437.2260\n",
      "\n",
      "Epoch 83 | Time: 3.00s\n",
      "  D_Loss: 0.325221 | G_Loss: 2.083703\n",
      "\n",
      "Epoch 84 | Time: 13.12s\n",
      "  D_Loss: 0.325153 | G_Loss: 2.089735\n",
      "  FID Score: 427.8093\n",
      "\n",
      "Epoch 85 | Time: 2.74s\n",
      "  D_Loss: 0.325370 | G_Loss: 2.085217\n",
      "\n",
      "Epoch 86 | Time: 11.72s\n",
      "  D_Loss: 0.325281 | G_Loss: 2.085991\n",
      "  FID Score: 440.0831\n",
      "\n",
      "Epoch 87 | Time: 2.39s\n",
      "  D_Loss: 0.325151 | G_Loss: 2.081824\n",
      "\n",
      "Epoch 88 | Time: 15.21s\n",
      "  D_Loss: 0.325257 | G_Loss: 2.085372\n",
      "  FID Score: 434.8479\n",
      "\n",
      "Epoch 89 | Time: 2.76s\n",
      "  D_Loss: 0.325206 | G_Loss: 2.089668\n",
      "\n",
      "Epoch 90 | Time: 11.73s\n",
      "  D_Loss: 0.325186 | G_Loss: 2.046164\n",
      "  FID Score: 439.7407\n",
      "\n",
      "Epoch 91 | Time: 2.80s\n",
      "  D_Loss: 0.325374 | G_Loss: 2.086104\n",
      "\n",
      "Epoch 92 | Time: 11.99s\n",
      "  D_Loss: 0.325170 | G_Loss: 2.083536\n",
      "  FID Score: 424.2500\n",
      "\n",
      "Epoch 93 | Time: 2.32s\n",
      "  D_Loss: 0.325224 | G_Loss: 2.109488\n",
      "\n",
      "Epoch 94 | Time: 12.13s\n",
      "  D_Loss: 0.325191 | G_Loss: 2.081868\n",
      "  FID Score: 422.2376\n",
      "\n",
      "Epoch 95 | Time: 2.74s\n",
      "  D_Loss: 0.325154 | G_Loss: 2.081299\n",
      "\n",
      "Epoch 96 | Time: 11.38s\n",
      "  D_Loss: 0.325173 | G_Loss: 2.027710\n",
      "  FID Score: 439.8537\n",
      "\n",
      "Epoch 97 | Time: 2.73s\n",
      "  D_Loss: 0.325256 | G_Loss: 2.090075\n",
      "\n",
      "Epoch 98 | Time: 12.90s\n",
      "  D_Loss: 0.325166 | G_Loss: 2.081265\n",
      "  FID Score: 437.9923\n",
      "\n",
      "Epoch 99 | Time: 2.58s\n",
      "  D_Loss: 0.325120 | G_Loss: 2.034239\n",
      "\n",
      "Epoch 100 | Time: 16.87s\n",
      "  D_Loss: 0.325267 | G_Loss: 2.087082\n",
      "  FID Score: 432.1105\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CGAN TRAINING COMPLETE\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cgan_gen, cgan_disc = train_cgan(\n",
    "    cgan_gen,\n",
    "    cgan_disc,\n",
    "    minority_loader,\n",
    "    minority_class_idx,\n",
    "    num_epochs=num_epochs,\n",
    "    latent_dim=latent_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ebfa3",
   "metadata": {},
   "source": [
    "Looking at the images the best epoch is 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e10442ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c9e4190c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directories for synthetic images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "\n",
    "# Create directories for synthetic images\n",
    "os.makedirs('synthetic_data/vanilla_gan', exist_ok=True)\n",
    "os.makedirs('synthetic_data/dcgan', exist_ok=True)\n",
    "os.makedirs('synthetic_data/cgan', exist_ok=True)\n",
    "\n",
    "print(\"Created directories for synthetic images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c8f640c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_31756\\2923563320.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_vanilla = torch.load('models/vanilla_gan/model_epoch_44.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded Vanilla GAN from epoch 44\n",
      "‚úì Loaded DCGAN from epoch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_31756\\2923563320.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_dcgan = torch.load('models/dcgan/model_epoch_44.pt')\n",
      "C:\\Users\\mamou\\AppData\\Local\\Temp\\ipykernel_31756\\2923563320.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_cgan = torch.load('models/cgan/model_epoch_92.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded CGAN from epoch 92\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "\n",
    "# Load Vanilla GAN \n",
    "vanilla_gen = VanillaGenerator(latent_dim=latent_dim, img_size=32).to(device)\n",
    "checkpoint_vanilla = torch.load('models/vanilla_gan/model_epoch_44.pt')\n",
    "vanilla_gen.load_state_dict(checkpoint_vanilla['generator_state_dict'])\n",
    "vanilla_gen.eval()\n",
    "print(\"‚úì Loaded Vanilla GAN from epoch 44\")\n",
    "\n",
    "# Load DCGAN \n",
    "dcgan_gen = DCGANGenerator(latent_dim=latent_dim, img_channels=3).to(device)\n",
    "checkpoint_dcgan = torch.load('models/dcgan/model_epoch_44.pt')\n",
    "dcgan_gen.load_state_dict(checkpoint_dcgan['generator_state_dict'])\n",
    "dcgan_gen.eval()\n",
    "print(\"‚úì Loaded DCGAN from epoch 44\")\n",
    "\n",
    "# Load CGAN \n",
    "num_classes = 3\n",
    "cgan_gen = CGANGenerator(latent_dim=latent_dim, num_classes=num_classes, img_channels=3).to(device)\n",
    "checkpoint_cgan = torch.load('models/cgan/model_epoch_92.pt')\n",
    "cgan_gen.load_state_dict(checkpoint_cgan['generator_state_dict'])\n",
    "cgan_gen.eval()\n",
    "print(\"‚úì Loaded CGAN from epoch 92\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2b22b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_images(generator, num_images, save_dir, gan_type='vanilla', minority_class_idx=None):\n",
    "    \"\"\"\n",
    "    Generate synthetic images and save them individually\n",
    "    \n",
    "    Args:\n",
    "        generator: trained generator model\n",
    "        num_images: number of images to generate\n",
    "        save_dir: directory to save images\n",
    "        gan_type: 'vanilla', 'dcgan', or 'cgan'\n",
    "        minority_class_idx: class index for CGAN\n",
    "    \"\"\"\n",
    "    generator.eval()\n",
    "    batch_size = 64  # Generate in batches to avoid memory issues\n",
    "    num_batches = (num_images + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Generating {num_images} images for {gan_type.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    img_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx in range(num_batches):\n",
    "            # Calculate batch size for last batch\n",
    "            current_batch_size = min(batch_size, num_images - img_count)\n",
    "            \n",
    "            # Generate noise\n",
    "            z = torch.randn(current_batch_size, latent_dim).to(device)\n",
    "            \n",
    "            # Generate images\n",
    "            if gan_type == 'cgan':\n",
    "                labels = torch.full((current_batch_size,), minority_class_idx, dtype=torch.long).to(device)\n",
    "                fake_imgs = generator(z, labels)\n",
    "            else:\n",
    "                fake_imgs = generator(z)\n",
    "            \n",
    "            # Save each image individually\n",
    "            for i in range(current_batch_size):\n",
    "                img = fake_imgs[i]\n",
    "                # Denormalize from [-1, 1] to [0, 1]\n",
    "                img = (img + 1) / 2\n",
    "                img = torch.clamp(img, 0, 1)\n",
    "                \n",
    "                # Save image\n",
    "                img_path = os.path.join(save_dir, f'synthetic_{img_count:05d}.png')\n",
    "                save_image(img, img_path)\n",
    "                img_count += 1\n",
    "            \n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"Generated {img_count}/{num_images} images...\")\n",
    "    \n",
    "    print(f\"‚úì Complete! Generated {img_count} images in {save_dir}\")\n",
    "    return img_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fbd9ae75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Generating 7400 images for VANILLA\n",
      "============================================================\n",
      "Generated 640/7400 images...\n",
      "Generated 1280/7400 images...\n",
      "Generated 1920/7400 images...\n",
      "Generated 2560/7400 images...\n",
      "Generated 3200/7400 images...\n",
      "Generated 3840/7400 images...\n",
      "Generated 4480/7400 images...\n",
      "Generated 5120/7400 images...\n",
      "Generated 5760/7400 images...\n",
      "Generated 6400/7400 images...\n",
      "Generated 7040/7400 images...\n",
      "‚úì Complete! Generated 7400 images in synthetic_data/vanilla_gan\n",
      "\n",
      "============================================================\n",
      "Generating 7400 images for DCGAN\n",
      "============================================================\n",
      "Generated 640/7400 images...\n",
      "Generated 1280/7400 images...\n",
      "Generated 1920/7400 images...\n",
      "Generated 2560/7400 images...\n",
      "Generated 3200/7400 images...\n",
      "Generated 3840/7400 images...\n",
      "Generated 4480/7400 images...\n",
      "Generated 5120/7400 images...\n",
      "Generated 5760/7400 images...\n",
      "Generated 6400/7400 images...\n",
      "Generated 7040/7400 images...\n",
      "‚úì Complete! Generated 7400 images in synthetic_data/dcgan\n",
      "\n",
      "============================================================\n",
      "Generating 7400 images for CGAN\n",
      "============================================================\n",
      "Generated 640/7400 images...\n",
      "Generated 1280/7400 images...\n",
      "Generated 1920/7400 images...\n",
      "Generated 2560/7400 images...\n",
      "Generated 3200/7400 images...\n",
      "Generated 3840/7400 images...\n",
      "Generated 4480/7400 images...\n",
      "Generated 5120/7400 images...\n",
      "Generated 5760/7400 images...\n",
      "Generated 6400/7400 images...\n",
      "Generated 7040/7400 images...\n",
      "‚úì Complete! Generated 7400 images in synthetic_data/cgan\n",
      "\n",
      "============================================================\n",
      "GENERATION SUMMARY\n",
      "============================================================\n",
      "Vanilla GAN: 7400 images\n",
      "DCGAN: 7400 images\n",
      "CGAN: 7400 images\n",
      "Total synthetic images: 22200\n"
     ]
    }
   ],
   "source": [
    "num_synthetic = 7400\n",
    "\n",
    "# Generate for Vanilla GAN\n",
    "count_vanilla = generate_synthetic_images(\n",
    "    vanilla_gen, \n",
    "    num_synthetic, \n",
    "    'synthetic_data/vanilla_gan',\n",
    "    gan_type='vanilla'\n",
    ")\n",
    "\n",
    "# Generate for DCGAN\n",
    "count_dcgan = generate_synthetic_images(\n",
    "    dcgan_gen,\n",
    "    num_synthetic,\n",
    "    'synthetic_data/dcgan',\n",
    "    gan_type='dcgan'\n",
    ")\n",
    "\n",
    "# Generate for CGAN (class 2 = Tuberculosis)\n",
    "count_cgan = generate_synthetic_images(\n",
    "    cgan_gen,\n",
    "    num_synthetic,\n",
    "    'synthetic_data/cgan',\n",
    "    gan_type='cgan',\n",
    "    minority_class_idx=minority_class_idx\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"GENERATION SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Vanilla GAN: {count_vanilla} images\")\n",
    "print(f\"DCGAN: {count_dcgan} images\")\n",
    "print(f\"CGAN: {count_cgan} images\")\n",
    "print(f\"Total synthetic images: {count_vanilla + count_dcgan + count_cgan}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
