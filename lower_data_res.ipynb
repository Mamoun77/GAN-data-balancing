{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aff47424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Image Dimensions (15421 images) ===\n",
      "Width  - Min: 384, Max: 4892, Avg: 884.2\n",
      "Height - Min: 127, Max: 4892, Avg: 757.5\n",
      "\n",
      "Aspect Ratio - Min: 0.76, Max: 3.38, Avg: 1.16\n",
      "File Size (MB) - Min: 0.01, Max: 7.44, Avg: 0.39\n",
      "\n",
      "=== Most Common Resolutions ===\n",
      "400×400: 8794 images\n",
      "4020×4892: 97 images\n",
      "4892×4020: 41 images\n",
      "3000×2939: 15 images\n",
      "3000×2945: 15 images\n",
      "\n",
      "=== Orientation ===\n",
      "Landscape: 6091, Portrait: 523, Square: 8807\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "SRC_DIR = \"data/high_res\"\n",
    "\n",
    "widths = []\n",
    "heights = []\n",
    "aspect_ratios = []\n",
    "file_sizes_mb = []\n",
    "image_count = 0\n",
    "\n",
    "for root, dirs, files in os.walk(SRC_DIR):\n",
    "    for filename in files:\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(root, filename)\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                w, h = img.size\n",
    "                widths.append(w)\n",
    "                heights.append(h)\n",
    "                aspect_ratios.append(w / h)\n",
    "                file_sizes_mb.append(os.path.getsize(img_path) / (1024 * 1024))\n",
    "                image_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {img_path} - {e}\")\n",
    "\n",
    "if image_count == 0:\n",
    "    print(\"No images found!\")\n",
    "    exit()\n",
    "\n",
    "print(f\"=== Image Dimensions ({image_count} images) ===\")\n",
    "print(f\"Width  - Min: {min(widths)}, Max: {max(widths)}, Avg: {np.mean(widths):.1f}\")\n",
    "print(f\"Height - Min: {min(heights)}, Max: {max(heights)}, Avg: {np.mean(heights):.1f}\")\n",
    "print(f\"\\nAspect Ratio - Min: {min(aspect_ratios):.2f}, Max: {max(aspect_ratios):.2f}, Avg: {np.mean(aspect_ratios):.2f}\")\n",
    "print(f\"File Size (MB) - Min: {min(file_sizes_mb):.2f}, Max: {max(file_sizes_mb):.2f}, Avg: {np.mean(file_sizes_mb):.2f}\")\n",
    "\n",
    "# Top 5 resolutions\n",
    "resolutions = Counter(zip(widths, heights)).most_common(5)\n",
    "print(f\"\\n=== Most Common Resolutions ===\")\n",
    "for (w, h), count in resolutions:\n",
    "    print(f\"{w}×{h}: {count} images\")\n",
    "\n",
    "# Orientation\n",
    "landscape = sum(r > 1 for r in aspect_ratios)\n",
    "portrait = sum(r < 1 for r in aspect_ratios)\n",
    "square = sum(r == 1 for r in aspect_ratios)\n",
    "print(f\"\\n=== Orientation ===\")\n",
    "print(f\"Landscape: {landscape}, Portrait: {portrait}, Square: {square}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340de6f1",
   "metadata": {},
   "source": [
    "**Chaning the Files from various different inconsistant and high reselutions to 128*128**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14d6033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# paths\n",
    "SRC_DIR = r\"C:\\My Projects\\GAN-data-balancing\\data\\high_res\"        # original dataset (class subfolders)\n",
    "DST_DIR = r\"C:\\My Projects\\GAN-data-balancing\\data\\low_res\"         # resized output\n",
    "IMG_SIZE = 128                   # target resolution\n",
    "\n",
    "os.makedirs(DST_DIR, exist_ok=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),            # resize shortest side to 128\n",
    "    transforms.CenterCrop(IMG_SIZE)         # crop to 128×128\n",
    "])\n",
    "\n",
    "for class_name in os.listdir(SRC_DIR):\n",
    "\n",
    "    # Skip universal_test folder\n",
    "    if class_name == \"universal_test\":\n",
    "        continue\n",
    "\n",
    "    src_class = os.path.join(SRC_DIR, class_name)\n",
    "    dst_class = os.path.join(DST_DIR, class_name)\n",
    "    os.makedirs(dst_class, exist_ok=True)\n",
    "\n",
    "    for img_name in os.listdir(src_class):\n",
    "        img_path = os.path.join(src_class, img_name)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = transform(img)\n",
    "        img.save(os.path.join(dst_class, img_name))\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2411d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source images: 15421\n",
      "Output images: 15421\n"
     ]
    }
   ],
   "source": [
    "print(f\"Source images: {sum(len(files) for _, _, files in os.walk(SRC_DIR))}\")\n",
    "print(f\"Output images: {sum(len(files) for _, _, files in os.walk(DST_DIR))}\")\n",
    "\n",
    "# the universal test images remained unchanged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
