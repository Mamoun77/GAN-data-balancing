{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf9166db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:01<00:00, 7.11MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 213kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.40MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Full training set (60k)\n",
    "full_train = datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Split: 50k train / 10k val\n",
    "train_set, val_set = random_split(full_train, [50000, 10000])\n",
    "\n",
    "test_set = datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57453edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 5923 samples\n",
      "Class 1: 6742 samples\n",
      "Class 2: 5958 samples\n",
      "Class 3: 6131 samples\n",
      "Class 4: 5842 samples\n",
      "Class 5: 5421 samples\n",
      "Class 6: 5918 samples\n",
      "Class 7: 6265 samples\n",
      "Class 8: 5851 samples\n",
      "Class 9: 5949 samples\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "dataset = datasets.MNIST(\n",
    "    root=\"./mnist\",\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "labels = dataset.targets.tolist()\n",
    "counts = Counter(labels)\n",
    "\n",
    "for cls in range(10):\n",
    "    print(f\"Class {cls}: {counts[cls]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7699cd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5923 Class 0 samples\n",
      "Saved all 5923 Class 0 samples to 'class_0_full.pt'\n",
      "Original dataset size: 60000\n",
      "Reduced dataset size: 57000\n",
      "Class 0 now has: 2923 samples\n",
      "Class 0: 2923 samples\n",
      "Class 1: 6742 samples\n",
      "Class 2: 5958 samples\n",
      "Class 3: 6131 samples\n",
      "Class 4: 5842 samples\n",
      "Class 5: 5421 samples\n",
      "Class 6: 5918 samples\n",
      "Class 7: 6265 samples\n",
      "Class 8: 5851 samples\n",
      "Class 9: 5949 samples\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.MNIST(\n",
    "    root=\"./mnist\",\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# Extract all Class 0 samples\n",
    "class_0_indices = [i for i, label in enumerate(dataset.targets) if label == 0]\n",
    "print(f\"Found {len(class_0_indices)} Class 0 samples\")\n",
    "\n",
    "# Save Class 0 data and labels\n",
    "class_0_data = torch.stack([dataset[i][0] for i in class_0_indices])\n",
    "class_0_labels = torch.tensor([dataset[i][1] for i in class_0_indices])\n",
    "\n",
    "torch.save({\n",
    "    'data': class_0_data,\n",
    "    'labels': class_0_labels,\n",
    "    'indices': class_0_indices\n",
    "}, 'class_0_full.pt')\n",
    "print(f\"Saved all {len(class_0_indices)} Class 0 samples to 'class_0_full.pt'\")\n",
    "\n",
    "# %%\n",
    "# Randomly remove 3000 samples from Class 0\n",
    "np.random.seed(42)  # for reproducibility\n",
    "indices_to_remove = np.random.choice(class_0_indices, size=3000, replace=False)\n",
    "indices_to_remove_set = set(indices_to_remove.tolist())\n",
    "\n",
    "# Create new dataset with reduced Class 0\n",
    "remaining_indices = [i for i in range(len(dataset)) if i not in indices_to_remove_set]\n",
    "\n",
    "# Create subset\n",
    "from torch.utils.data import Subset\n",
    "reduced_dataset = Subset(dataset, remaining_indices)\n",
    "\n",
    "print(f\"Original dataset size: {len(dataset)}\")\n",
    "print(f\"Reduced dataset size: {len(reduced_dataset)}\")\n",
    "print(f\"Class 0 now has: {len(class_0_indices) - 3000} samples\")\n",
    "\n",
    "# Verify class distribution\n",
    "reduced_labels = [dataset.targets[i].item() for i in remaining_indices]\n",
    "from collections import Counter\n",
    "new_counts = Counter(reduced_labels)\n",
    "for cls in range(10):\n",
    "    print(f\"Class {cls}: {new_counts[cls]} samples\")\n",
    "\n",
    "# %%\n",
    "# Use reduced_dataset for training\n",
    "train_set, val_set = random_split(reduced_dataset, [47000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01187338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Class 0 has 2923 samples\n",
      "Saved reduced Class 0 (2923 samples) to 'class_0_reduced.pt'\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Save the reduced Class 0 separately\n",
    "reduced_class_0_indices = [i for i in class_0_indices if i not in indices_to_remove_set]\n",
    "print(f\"Reduced Class 0 has {len(reduced_class_0_indices)} samples\")\n",
    "\n",
    "reduced_class_0_data = torch.stack([dataset[i][0] for i in reduced_class_0_indices])\n",
    "reduced_class_0_labels = torch.tensor([dataset[i][1] for i in reduced_class_0_indices])\n",
    "\n",
    "torch.save({\n",
    "    'data': reduced_class_0_data,\n",
    "    'labels': reduced_class_0_labels,\n",
    "    'indices': reduced_class_0_indices\n",
    "}, 'class_0_reduced.pt')\n",
    "print(f\"Saved reduced Class 0 ({len(reduced_class_0_indices)} samples) to 'class_0_reduced.pt'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
